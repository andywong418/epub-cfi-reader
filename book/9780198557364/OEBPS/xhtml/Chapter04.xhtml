<?xml version="1.0" encoding="utf-8"?><!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en" lang="en"><head><meta charset="utf-8"/><title>Applications of Artificial Intelligence in Chemistry</title><link rel="stylesheet" href="../styles/stylesheet.css" type="text/css"/><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></head><body><a id="page_62" class="page" style="width:70%;">page 62, Genetic algorithms</a><section epub:type="chapter" id="Ch04"><h1 class="main"><b>4&#160;&#160;&#160;&#160;Genetic algorithms</b></h1><section epub:type="chapter" id="sec_4.1"><h2 class="h2"><b>4.1&#160;&#160;Introduction</b></h2><p class="noindent">It can be difficult and frustrating trying to solve scientific problems. The difficulties arise for a variety of reasons. Some problems are so obscure that it seems impossible to discover any answer to them at all. Other problems present just the opposite difficulty: they offer us a huge over-supply of answers, within which the best is hidden under a multitude of inferior competitors.</p><p class="indent3-ka1">Many scientific problems, such as the determination of the conformation of macromolecules, fall in this second category. Often there are several different approaches available to tackle these problems; among the most productive are techniques capable of sophisticated searching.</p><p class="indent3-ka1">The genetic algorithm (GA) is just such a technique &#x2013; an intelligent way to search for the optimum solution to a problem hidden in a wealth of poorer ones.</p><p class="indent3-ka1t"><i>The genetic algorithm is an optimization technique based on evolutionary principles</i>.</p><p class="indent3-ka1t">Evolutionary ideas and terminology pervade the GA. The algorithm works with a &#x2018;population&#x2019; of individuals, each of which is a candidate solution to the problem; these individuals &#x2018;mate&#x2019; with each other, &#x2018;mutate&#x2019;, and &#x2018;reproduce&#x2019; and in this way evolve through successive generations towards an optimum solution.</p><p class="indent3-ka1">It is curious that evolution should provide the inspiration for solving numerical problems, and remarkable that it forms the basis for a method of great power and versatility. In this chapter we shall learn what characteristics of evolution give it this ability, and how its power can be harn a most effective and intriguing way.</p></section><section epub:type="chapter" id="sec_4.2"><h2 class="h2"><b>4.2&#160;&#160;What can the GA do?</b></h2><p class="noindent">At first sight problems in science that involve searching seem rare in comparison with those that require other kinds of computation, such as quantum mechanical or statistical calculations. However, this impression is misleading. Searching problems appear uncommon only because they are usually presented in a form that obscures the fact that very many solutions to them actually exist.</p><p class="indent3-ka1">These problems span a wide range; for example:</p><a id="page_63" class="page" style="width:70%;">page 63, Genetic algorithms</a><p class="indent3-ka1"><img src="../images/page63-1.jpg" alt="images"/>&#160;&#160;&#160;<i>How can one calculate the geometry that a molecule will adopt to minimize its free energy?</i> The energy of interaction between neighbouring groups in a molecule depends on the interatomic dihedral (torsional) angles and distances between the groups (<a href="#fig_4.1">Fig. 4.1</a>), so different conformers (arrangements of atoms in space) have different total energies. The techniques of quantum mechanics can in principle identify the optimum conformations, but for molecules of the size of proteins these are very large-scale calculations indeed, and AI searching algorithms may be superior to quantum mechanical methods.</p><aside class="abc" style="margin-top:-7em;" epub:type="sidebar"><p class="noindent2">Of the infinite number of conformers possible for a large molecule, only one or a few will have the minimum energy.</p></aside><figure style="margin-left:-7em;" id="fig_4.1"> <img src="../images/page63-2.jpg" alt="images"/><figcaption style="margin-top:1em;"><b>Fig. 4.1</b> The energy of a molecule depends upon its torsional angles.</figcaption></figure><p class="noindent">&#160;</p><p class="indent3-ka1"><img src="../images/page63-1.jpg" alt="images"/>&#160;&#160;&#160;<i>A UV/visible absorption spectrum is the sum of band spectra that arise from different electronic transitions; how can the underlying spectra be found?</i> The number of bands composing a UV/visible spectrum may be small, but there are many ways to decompose the spectrum, depending upon the assumptions made about the number and shape of the underlying bands. These assumptions may rest on a rather flimsy theoretical base, and if they are incorrect, it may prove impossible to satisfactorily resolve the spectrum.</p><figure style="margin-left:-5em;" id="fig_4.2"> <img src="../images/page63-3.jpg" alt="images"/><figcaption style="margin-top:1em; margin-left:2em;"><b>Fig. 4.2</b> A UV/visible spectrum decomposed in two different ways into possible underlying spectra.</figcaption></figure><a id="page_64" class="page" style="width:70%">page 64, Genetic algorithms</a><p class="indent3-ka1"><img src="../images/page63-1.jpg" alt="images"/>&#160;&#160;&#160;<i>How many isomers of C<sub>26</sub>H<sub>52</sub>O are ethers containing just one six-membered ring?</i> In principle we can determine how many isomers contain certain functional groups by drawing the structure of each isomer and checking to see whether it contains the features of interest. However, the number of isomers sharing this formula is very large and only a tiny fraction of these are ethers containing a six-membered ring, so that in practice this procedure is impossibly time-consuming.</p><p class="indent3-ka1t">At the heart of each of these problems is the need to single out a few optimum solutions from the large number of possible solutions available; they suggest the diversity and complexity of searching tasks. We recall from <a href="Chapter01.xhtml#Ch01">Chapter 1</a> that AI is increasingly the method of choice for solving large-scale, complex problems, so, when problems of this sort arise in science, there should be a role for intelligent algorithms in finding a solution of acceptable quality.</p></section><p class="noindent">&#160;</p><section epub:type="chapter" id="sec_4.3"><h2 class="h2"><b>4.3&#160;&#160;What makes the genetic algorithm different from other methods?</b></h2><p class="noindent">Any computational task (or chemical task, for that matter), which involves mating, mutation, and reproduction sounds definitely odd, if not illicit, so you will not be surprised to discover that the GA has little in common with most other optimization and search methods. The major differences between it and conventional methods are:</p><p class="indent3-ka1t">&#8226;&#160;&#160;&#160;<i>The GA is a stochastic algorithm, not a deterministic one</i>.</p><aside class="abc" style="margin-top:-5em;" epub:type="sidebar"><figure style="margin-left:0em;" id="fig_4.3"> <img src="../images/page64-1.jpg" alt="images"/><figcaption class="noindent2" style="margin-top:1em;"><b>Fig. 4.3</b> How hill-climbing finds the maximum on a surface.</figcaption></figure></aside><p class="indent3-ka1">Suppose the solutions to a problem lie on the surface shown in <a href="#fig_4.3">Fig. 4.3</a>. A conventional algorithm searching for the optimum solution (the maximum on the surface) will investigate it in a clearly-defined and predictable fashion. For example, in &#x2018;steepest-ascent hill-climbing&#x2019;, one of the most widely-used conventional algorithms, an arbitrary starting point is chosen; the gradient at this point is found and used to define which direction is &#x2018;up&#x2019;. A short step &#x2018;upwards&#x2019; is taken and the gradient found at the new location. This procedure is repeated until a maximum is reached; hill-climbing then terminates.</p><p class="indent3-ka1">This procedure is <b>deterministic</b>, because the behaviour of the hill-climber is fully determined by the rules that govern its operation. The existence of these rules means that we can predict before starting exactly how the algorithm will function. Furthermore, its behaviour is completely invariant, so every climb of the same surface starting from the same point follows exactly the same route. For very simple surfaces hill-climbing is fast and reliable, but it encounters serious and sometimes fatal difficulties when confronted with surfaces containing multiple maxima, or significant noise.</p><aside class="abc" style="margin-top:-6em;" epub:type="sidebar"><p class="noindent2">It should be clear that hill-climbing will often find a local maximum, rather than the global maximum, on a surface.</p></aside><p class="indent3-ka1">In the former case (<a href="#fig_4.4">Fig. 4.4</a>) there may be too many hills to climb. Where should the search begin? And, once it has found the top of a hill, how does it know there is not a slightly higher hill lurking close by?</p><figure style="margin-left:-7em;" id="fig_4.4"><a id="page_65" class="page" style="width:85%">page 65, Genetic algorithms</a> <img src="../images/page65-1.jpg" alt="images"/><figcaption style="margin-top:1em;"><b>Fig. 4.4</b> A surface with numerous maxima.</figcaption></figure><aside class="abc" style="margin-top:-10em;" epub:type="sidebar"><p class="noindent2"><a href="#fig_4.4">Fig 4.4</a> shows a small portion of a complicated surface, derived from studies of flowshop scheduling. There are roughly 10<sup>15</sup> maxima in all.</p></aside><p class="indent3-ka1">In <a href="#fig_4.5">Fig. 4.5</a> the noise makes it hard for a hill-climber to know which direction is &#x2018;up&#x2019;; it may rapidly become trapped by a peak consisting of more noise than signal.</p><figure style="margin-left:-7em;" id="fig_4.5"> <img src="../images/page65-2.jpg" alt="images"/><figcaption style="margin-top:1em;"><b>Fig. 4.5</b> A surface containing substantial noise.</figcaption></figure><aside class="abc" style="margin-top:-15em;" epub:type="sidebar"><p class="noindent2"><a href="#fig_4.5">Fig 4.5</a> shows experimental data derived from studies of kinetics by electron spin resonance.</p></aside><p class="indent3-ka1">By contrast, the GA is <b>stochastic</b>. A stochastic process relies upon random elements (&#x2018;chance&#x2019;) in parts of its operation. This is illustrated by <a href="#fig_4.6">Fig. 4.6</a>, which shows two GA searches of the same surface. Both searches reach the maximum, but, though they started from the same point, they pursue quite different routes, since at each point visited random factors influence the decision that the algorithm takes on where to move next.</p><aside class="abc" style="margin-top:-6em;" epub:type="sidebar"><figure style="margin-left:0em;" id="fig_4.6"> <img src="../images/page65-3.jpg" alt="images"/><figcaption style="margin-top:1em;"><b>Fig. 4.6</b> Routes that might be taken by a GA searching the surface shown in <a href="#fig_4.3">Fig. 4.3</a>.</figcaption></figure></aside><p class="indent3-ka1">On the face of it this seems to be an inefficient way to search; if there is a best way to climb the surface, why not use it? The difficulty is that the &#x2018;best&#x2019; route is usually unknown; hill-climbing presumes that the fastest way to the top is via the steepest hill, but although this is one method of locating hilltops, it is not the only one. Any deterministic method such as hill-climbing is certain to meet surfaces which defeat its rules, and it will then be inexorably<a id="page_66" class="page">page 66, Genetic algorithms</a>lured into the same trap on the surface every time it is run (<a href="#fig_4.7">Fig. 4.7</a>). A randomized method like the GA is less likely to be misled by such traps, and if the search stumbles into one, a mechanism exists whereby it can escape and the search be resumed elsewhere.</p><figure style="margin-left:-7em;" id="fig_4.7"> <img src="../images/page66-1.jpg" alt="images"/><figcaption style="margin-top:1em;"><b>Fig. 4.7</b> A surface which would defeat a hill-climber.</figcaption></figure><p class="indent3-ka1"><img src="../images/page63-1.jpg" alt="images"/>&#160;&#160;<i>The GA investigates many possible solutions simultaneously; each investigation learns about a different region of the surface.</i></p><p class="indent3-ka1">It is as though numerous hill-climbers were wandering around on the surface at the same time, each one having started from a different, randomly-chosen position.</p><aside class="abc" style="margin-top:-1em;" epub:type="sidebar"><p class="noindent2">This is reminiscent of the communal memory in an artificial neural network. However, though an application requires just one neural network, in the GA the whole population works co-operatively, and all individuals together constitute the memory. There must be value in numbers, and we shall shortly see why this is so.</p></aside><p class="indent3-ka1">It may seem counter-productive to spend time investigating many solutions if there is only a single right one, or a few, but these multiple GA solutions are not independent of one another; instead the GA treats all solutions as a group. This group finds better answers than a single search on its own can, and finds them more quickly, because each solution can communicate with others in the group (as we shall see, this is where the &#x2018;mating&#x2019; comes in). When one solution begins to move towards a good solution, information about this improvement is disseminated through the rest of the population, and other solutions use and benefit from this new knowledge. In effect a collective memory develops, spread among many solutions. Communication and interaction of this sort, the nature of which will become clear shortly, are essential features of the GA and are fundamental to its success.</p><p class="indent3-ka1t"><img src="../images/page63-1.jpg" alt="images"/>&#160;&#160;&#160;<i>The GA requires no auxiliary information about a surface, such as the gradient at a point</i>.</p><p class="indent3-ka1">This is a crucial advantage, which greatly extends the range of problems that the GA can tackle. Calculus-based methods depend upon the existence of derivatives, and numerical hill-climbers require that the gradient at any point gives reliable information about which direction is &#x2018;up&#x2019;.</p><a id="page_67" class="page" style="width:70%;">page 67, Genetic algorithms</a><p class="indent3-ka1">This is often not the case in noisy scientific data, and hill-climbers have severe difficulty travelling across surfaces such as that shown in <a href="#fig_4.5">Fig. 4.5</a>. By contrast, the GA is little troubled by the presence of even substantial noise, and completely unaffected by the absence of derivatives.</p></section><section epub:type="chapter" id="sec_4.4"><h2 class="h2"><b>4.4&#160;&#160;The genetic algorithm: the mechanics</b></h2><p class="noindent">Although the GA is based upon the concepts of evolution and is full of evolutionary terminology, evolution-based methods are logical, not biological, in nature. Every individual in a GA <b>population</b> is a distinct <i>numerical</i> solution to the problem; these individuals are subjected to evolution-like operations, but no understanding of biology is necessary to understand how these processes work. It is these evolutionary manipulations &#x2013; the mechanics of the GA &#x2013; that we now consider.</p><p class="indent3-ka1" style="margin-bottom:2em;">The GA is a cyclic process, in which a sequence of operations is executed repeatedly in an attempt to drive the search toward optimum solutions. Each cycle, in which a population of solutions is first assessed for fitness, then reproduced and adapted, constitutes a <b>generation</b> and consists of the following steps:</p><div class="border"><p class="boxtitlec" style="margin-left:5em;"><b>The genetic algorithm</b></p><p class="boxhang" style="margin-top:1em;">1. On the first cycle only, form a starting population of <b>chromosomes</b> or <b>strings</b>. These are candidate solutions to the problem.</p><p class="boxhang">2. Determine how good a solution each string is. Stop if a high-quality solution exists, or the maximum number of generations has passed.</p><p class="boxhang">3. Determine the <b>fitness</b> of each string from its quality.</p><p class="boxhang">4. Use a <b>reproduction operator</b> to form a new population by selecting strings from the current population with a probability determined by their fitness.</p><p class="boxhang">5. Choose pairs of strings at random and combine them using a cut-and-pasting procedure defined by a <b>mating</b> or <b>crossover operator</b>.</p><p class="boxhang">6. Alter a few members of the population using a <b>mutation operator</b>.</p><p class="boxhang" style="margin-bottom:1em;">7. Return to step 2.</p></div><aside class="abc" style="margin-top:-12em;" epub:type="sidebar"><p class="noindent2">A typical GA calculation requires hundreds or thousands of these cycles to evolve good answers.</p></aside><p class="indent3-ka1t">It is not obvious that the procedure outlined in the box is capable of doing anything useful at all, let alone solving complex scientific problems. Nor is it clear why this set of steps deserves to be called &#x2018;intelligent&#x2019;. To appreciate these points, we will consider each step in more detail, illustrating the operation of the GA as we do so by applying it to a chemical problem.</p><a id="page_68" class="page" style="width:70%">page 68, Genetic algorithms</a><h3 class="h3"><b>Prepare the initial population</b></h3><p class="noindent">A string is an ordered sequence of numbers which in some way represents a solution to a problem; the terms &#x2018;string&#x2019; and &#x2018;chromosome&#x2019; are used interchangeably in GA work. By analogy with natural systems, each position within a string is known as a <b>gene</b>, and its value, an <b>allele</b>.</p><p class="indent3-ka1">Suppose we wished to use the GA to find the optimum conformation of the fluoroalkane shown in <a href="#fig_4.8a">Fig. 4.8(a)</a>, 3,5-difluoroheptane.</p><figure style="margin-left:-9em;" id="fig_4.8a"> <img src="../images/page68-1.jpg" alt="images"/><figcaption style="margin-left:2em; margin-top:1em;"><b>Fig. 4.8</b>(a) We will use the GA to find the optimum conformation of this molecule.</figcaption></figure><p class="indent3-ka1t">The bond angles at each carbon atom are tetrahedral, and the bond lengths are largely independent of stereochemistry, so one conformer is distinguished from another only by the values of its dihedral angles. Any conformer can be identified uniquely by specifying these dihedral angles in order {&#x03B1;<sub>1</sub>, &#x03B1;<sub>2</sub>, &#x03B1;<sub>3</sub>, &#x03B1;<sub>4</sub>, &#x03B1;<sub>5</sub>, &#x03B1;<sub>6</sub>,} so that {183, 165, 313, 253, 294, 84} for example, represents the conformer shown in <a href="#fig_4.8b">Fig. 4.8(b)</a>. This set of numbers constitutes a string, and it is numerical representations of this sort that will be manipulated by the operators within the algorithm.</p><figure style="margin-left:-9em;" id="fig_4.8b"> <img src="../images/page68-2.jpg" alt="images"/><figcaption class="noindent2" style="margin-left:14em; margin-top:1em;"><b>Fig. 4.8</b>(b) A randomly-chosen conformer of the fluoroheptane.</figcaption></figure><a id="page_69" class="page" style="width:70%;">page 69, Genetic algorithms</a><p class="indent3-ka1">Each angle can take any value within the range 0 to 359&#x00B0; (0&#x00B0; and 360&#x00B0; are, of course, equivalent), so there is strictly an infinite number of possible conformations. (There are about 10<sup>15</sup> conformations if, as in this example calculation, we restrict the angles to integer values; there is also some degeneracy among solutions, but 10<sup>15</sup> is still rather a large number of solutions to look through to find the best ones.)</p><aside class="abc" style="margin-top:-6.5em;" epub:type="sidebar"><p class="noindent2">The problem described here is related to the important &#x2018;protein-folding problem&#x2019;. The development of new drugs relies increasingly on quantum mechanical studies of the strength with which a potential drug binds to a target protein molecule. Such studies can help narrow the range of molecules whose development might be worth pursuing, and thus control the costs of their synthesis and laboratory trial. The calculations depend for success on a reliable knowledge of protein stereochemistry, in particular in the region of the active site. The structure of proteins is difficult to determine experimentally, so extensive efforts are being made to calculate how a protein folds to minimize its free energy, and thus determine the stereochemistry around the active site. This calculation is of great complexity, but is of enormous academic and commercial interest.</p></aside><p class="indent3-ka1">It is the task of the GA, starting from a number of random conformations of this sort, to transform these into good &#x2013; and ultimately optimum &#x2013; conformations. In pursing this goal, the GA uses several simple operators to manipulate strings. The first step in the calculation is to form an initial population of strings, by selecting random conformers. We must therefore decide how many strings constitute a population.</p><p class="indent3-ka1">As generation succeeds generation, the angles that make up the strings change as they are manipulated by the algorithm; the strings gradually evolve in this way towards good solutions. Just as in biological systems, fruitful evolution requires variety in the population, and GA experiments show that populations containing just a handful of strings cannot provide the diversity on which evolution thrives; this effectively provides a lower limit to the population size.</p><p class="indent3-ka1">On the other hand, though a very large population should be diverse, good strings may then find themselves overwhelmed by a flood of marginally poorer strings, and the calculation will be slow to converge. This suggests that there is also an upper limit on population size. Bearing in mind these restrictions, populations containing 25&#x2013;100 strings are usual in GA work.</p><p class="indent3-ka1">For the fluoroalkane calculation we will use a population of slightly smaller size than is normal, since this will adequately illustrate the mechanics of the algorithm. As we shall see, even this small population will rapidly discover near-optimum conformations.</p><p class="indent3-ka1">We form the members of the first generation by choosing at random six angles in the range 0 &#x2264; &#x03B1; &#x2264; 359 for each conformer in a total population of ten. These starting strings are shown in <a href="#tab4.1">Table 4.1</a>.</p><p class="indent3-ka1">The goal of the GA is to find a solution in which all dihedral angles are at, or close to, their optimum values, at which the interaction energy between the groups separated by those angles is at a minimum. These energies (in arbitrary units) depend upon the dihedral angles between the groups in the fashion depicted in <a href="#fig_4.9">Fig. 4.9</a>. Angles in the shaded regions correspond to an interaction energy within 2 per cent of the minimum. <a href="#fig_4.9">Figure 4.9</a> shows that a &#x2018;good&#x2019; angle between a methyl group and a methylene group is one in the range 55&#x00B0;&#x2013;65&#x00B0;, 175&#x00B0;&#x2013;185&#x00B0;, or 295&#x00B0;&#x2013;305&#x00B0;, and for the CHF&#x2013;CH<sub>2</sub> interaction &#x2018;good&#x2019; angles are those between 175&#x00B0; and 185&#x00B0; inclusive. In <a href="#tab4.1">Table 4.1</a> the good angles defined in this way in the first population have been shown in bold face. As we would expect, since the angles that constitute the strings in this population were chosen at random, there are few good angles at this stage.</p><a id="page_70" class="page" style="width:70%;">Page 70, Genetic algorithms</a><p class="tabcap" id="tab4.1" style="margin-bottom:-1em;"><b>Table 4.1</b> The strings in generation 1.</p><figure style="margin-left:-11.5em;"><img src="../images/page70-1.jpg" alt="images"/></figure><p class="noindent">&#160;</p><h3 class="h3"><b>Determine the quality of the strings</b></h3><p class="noindent">Once a starting population has been chosen, each string must be inspected to determine its quality. Since the most stable conformer is that of lowest interaction energy, a high-quality solution to this problem is one of low energy.</p><aside class="abc" style="margin-top:-1em;" epub:type="sidebar"><p class="noindent2">The &#x2018;quality&#x2019; of a string is simply a measure of how good a solution it is.</p></aside><p class="indent3-ka1">The total interaction energy for a given string is the sum of the energies arising from interactions between neighbouring &#x2013;CHF&#x2013; and &#x2013;CH<sub>2</sub>&#x2013; groups, and between neighbouring &#x2013;CH<sub>2</sub>&#x2013; and &#x2013;CH<sub>3</sub> groups along the carbon backbone of the molecule. Although interactions between non-neighbouring groups are not zero, they are smaller than interactions between neighbours, and we shall ignore them. This is only a minor approximation and makes no difference to either the principles of the calculation or its success.</p><p class="indent3-ka1">We can use <a href="#fig_4.9">Fig. 4.9</a> to estimate the total interaction energy for a conformer by summing the energies associated with each pairwise interaction. For example, for string 1 the energy associated with dihedral angle &#x03B1;<sub>1</sub> is 0.19, that with dihedral angle &#x03B1;<sub>2</sub> is 0.66, and so on. The total energy is then given by:</p><figure style="margin-left:-5em;" id="fig_4.9"><a id="page_71" class="page" style="width:82%;">Page 71, Genetic algorithms</a><img src="../images/page71-1.jpg" alt="images"/><figcaption style="margin-top:1em;margin-left:7em;width:73%;"><b>Fig. 4.9</b> The dependence of the interaction energy upon dihedral angle for the methyl-methylene (left) and the methylene-fluoromethylene (right) interactions.</figcaption></figure><p class="centerd2" style="margin-top:3em;"><i>E<sub>i</sub></i> = 0.19+0.66+0.95+2.68+0.65+1.37 = 6.50</p><p class="indent3-ka1">In this way the total energy for each string in the starting population can be calculated, and these are shown in <a href="#tab4.1">Table 4.1</a>.</p><aside class="abc" style="margin-top:-2.5em;" epub:type="sidebar"><p class="noindent2">In performing this calculation we must remember that &#x03B1;<sub>1</sub> and &#x03B1;<sub>6</sub> refer to methyl-methylene interactions, and that all other angles refer to methylene-fluoromethylene interactions.</p></aside><p class="indent3-ka1">Determination of the quality of each solution is the only point of contact between the algorithm itself and the physical problem that it is set to solve &#x2013; it is the only kind of information that the GA needs. Most searching algorithms require access to extra information. For example, numerical hill-climbers need to know the gradient of the surface at every point that they visit so that they can decide in which direction to take their next step. This extra information may be missing (on a fragmented surface, for example), or it may be misleading (on a noisy surface). Even when the information is available, time is required to find or to calculate it.</p><p class="indent3-ka1">By contrast, the GA is not concerned with the nature of the immediate (or distant) environment around a point; it needs to know only how &#x2018;good&#x2019; a solution that point represents. In principle this information is always available, (the problem would be insoluble if a good solution could not be distinguished from a bad one), so the GA can in theory search a great variety of surfaces.</p><p class="indent3-ka1">That the GA has such a limited appetite for knowledge about the problem is an important advantage over other methods. It makes the GA a very general method of analysis indeed, and in this respect it has much in common with neural networks. Just as a single neural network can be trained to solve any one of numerous different types of problem, a single GA program can be adapted to undertake a wide range of tasks through minor changes in computer code.</p><a id="page_72" class="page" style="width:70%;">Page 72, Genetic algorithms</a><h3 class="h3"><b>Determine the fitness of the strings</b></h3><aside class="abc" style="margin-top:2em;" epub:type="sidebar"><p class="noindent2">This is the first appearance in the GA of a factor which drives the algorithm towards optimum solutions.</p></aside><p class="noindent">Evolution embodies the principle of &#x2018;survival of the fittest&#x2019;: &#x2018;fit&#x2019; organisms in one generation generally manage to leave behind progeny for the next, while &#x2018;unfit&#x2019; ones often do not. In GA terms, unfit strings are those representing poor solutions, and their continued presence in the population will hinder the calculation. Under a survival of the fittest scheme, unfit strings usually fail to live for more than a few generations beyond their first appearance, as fit strings take their place. Evolution-like manipulations in this way massage the population and encourage the growth of good solutions, as inferior ones are weeded out.</p><p class="indent3-ka1">Survival of the fittest is a key element of the GA, and to put it into practice we must derive a relationship between the quality of a string, which we already know, and its fitness, which we require. This is an important step, since the rate at which the algorithm converges will be affected by the relationship chosen.</p><aside class="abc" style="margin-top:-5em;" epub:type="sidebar"><p class="noindent2">The selection of an appropriate relationship between quality and fitness becomes easier with experience, and in simple problems, such as the present one, choice of a good relationship is in any case not difficult.</p></aside><p class="indent3-ka1">The relationship must suitably reward good solutions with high fitness if these solutions are to thrive; beyond that criterion, the relationship is essentially arbitrary. It is not hidden away somewhere, waiting for us to discover it, nor is it predefined by the constraints of the problem; instead, any recipe can be chosen. In this problem fitness is inversely related to quality (as the energy decreases, the strings get better), and we shall choose to relate <i>fi</i>, the fitness of string <i>i</i>, to <i>E<sub>i</sub></i>, its energy using the function:</p><p class="eqn" style="margin-top:1em;"><i>f<sub>i</sub></i> = 1.0/(<i>E<sub>i</sub></i>&#x2013;0.9)<span class="no">(4.1)</span></p><p class="indent3-ka1t">(The purpose of the 0.9 in eqn (4.1) is to accentuate the difference in fitness between good and poor quality strings. If fitness were defined simply as the inverse of the energy, the best possible string would have a fitness of 1.042 since the minimum energy is 0.96; the worst possible string would have a fitness of 0.047. Using eqn (4.1), the maximum fitness is 16.667, and the minimum fitness is 0.049. The increased spread of fitness that the introduction of the 0.9 in eqn (4.1) provides has the effect of putting extra evolutionary pressure on the poor strings; this will result in them being removed from the population more effectively, which in turn speeds convergence.)</p><p class="indent3-ka1">The fitnesses of strings in the first generation calculated through use of eqn (4.1) are shown in the final column of <a href="#tab4.1">Table 4.1</a></p><h3 class="h3a"><b>Which strings shall reproduce?</b></h3><aside class="abc" style="margin-top:-2em;" epub:type="sidebar"><p class="noindent2">The first population appeared through a sort of immaculate conception, but subsequently each fresh population must be derived from the previous one.</p></aside><p class="noindent">The GA works in a series of generations, in each of which a population is formed, then allowed to reproduce. The first step in this process is the selection of parent strings for reproduction.</p><p class="indent3-ka1">In this, we follow evolution rather closely. Fit organisms are generally successful in transmitting their genes from one generation to the next, while unfit ones usually are not. It was with this in mind that we calculated the<a id="page_73" class="page">Page 73, Genetic algorithms</a>fitness for every string; parents are now selected from the current generation on the basis of that fitness.</p><p class="indent3-ka1">Survival of the fittest provides guidelines by which to construct the next generation, but it is not a completely deterministic recipe: sometimes poorly-adapted individuals manage to leave offspring, despite their unpromising fitness; sometimes fit individuals fail to do so. So, it would not be appropriate to uncritically choose for the next generation every string with high fitness and disregard all those with low fitness. A method of selection is needed which, while biased in favour of highly fit strings, still gives unfit strings some chance of reproducing.</p><aside class="abc" style="margin-top:-7em;" epub:type="sidebar"><figure style="margin-left:0em;" id="fig_4.10"><img src="../images/page73-1.jpg" alt="images"/><figcaption class="noindent2" style="margin-top:1em; margin-left:0em;"><b>Fig. 4.10</b> The roulette wheel, which functions as a reproduction operator.</figcaption></figure></aside><p class="noindent">&#160;</p><h3 class="h3"><b>The roulette wheel</b></h3><p class="noindent">A simple way to accomplish this is to use a roulette wheel. We construct an imaginary roulette wheel in which each string is allocated a slot with a width proportional to the string&#x2019;s fitness (<a href="#fig_4.10">Fig. 4.10</a>). The wheel is spun, and the string into whose slot the imaginary ball falls is copied once into the new generation. This process is repeated until the number of copies made equals the population size.</p><p class="indent3-ka1">The roulette wheel mechanism clearly meets both the requirement that fit strings have the best chance of reproduction (since they have the widest slots), and that unfit strings have a lesser but non-zero chance of being copied. A string of exactly average fitness has an even chance of being copied once into the next generation, so we can calculate the number of copies of each string that the roulette wheel should generate by scaling the fitnesses so that the average is 1.0. The scaled fitness then equals the expected number of copies of that string in the new generation. <a href="#tab4.2">Table 4.2</a> shows these scaled fitnesses, and also shows the actual number of copies that the roulette wheel mechanism generated for our illustrative calculation (which, of course, must be a whole number for each string).</p><aside class="abc" style="margin-top:-15em;" epub:type="sidebar"><p class="noindent2" id="tab4.2"><b>Table 4.2</b> Scaled fitnesses and number of copies made by the roulette wheel.</p><table class="width70tb"><tr><td style="vertical-align:top;" class="borbw15"><p class="tabled">string</p></td><td style="vertical-align:top;" class="borbw35"><p class="tabled">Fitness</p></td><td style="vertical-align:top;" class="borbw35"><p class="tabled">Scaled fitness</p></td><td style="vertical-align:top;" class="borbw15"><p class="tabled">Copies</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">1</p></td><td style="vertical-align:top;"><p class="tablec1">0.180</p></td><td style="vertical-align:top;"><p class="tablec1">1.650</p></td><td style="vertical-align:top;"><p class="tablec1">2</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">2</p></td><td style="vertical-align:top;"><p class="tablec1">0.069</p></td><td style="vertical-align:top;"><p class="tablec1">0.636</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">3</p></td><td style="vertical-align:top;"><p class="tablec1">0.111</p></td><td style="vertical-align:top;"><p class="tablec1">1.018</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">4</p></td><td style="vertical-align:top;"><p class="tablec1">0.086</p></td><td style="vertical-align:top;"><p class="tablec1">0.789</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">5</p></td><td style="vertical-align:top;"><p class="tablec1">0.164</p></td><td style="vertical-align:top;"><p class="tablec1">1.505</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">6</p></td><td style="vertical-align:top;"><p class="tablec1">0.072</p></td><td style="vertical-align:top;"><p class="tablec1">0.661</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">7</p></td><td style="vertical-align:top;"><p class="tablec1">0.092</p></td><td style="vertical-align:top;"><p class="tablec1">0.844</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">8</p></td><td style="vertical-align:top;"><p class="tablec1">0.119</p></td><td style="vertical-align:top;"><p class="tablec1">1.092</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">9</p></td><td style="vertical-align:top;"><p class="tablec1">0.136</p></td><td style="vertical-align:top;"><p class="tablec1">1.248</p></td><td style="vertical-align:top;"><p class="tablec1">1</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">10</p></td><td style="vertical-align:top;"><p class="tablec1">0.061</p></td><td style="vertical-align:top;"><p class="tablec1">0.560</p></td><td style="vertical-align:top;"><p class="tablec1">0</p></td></tr></table></aside><p class="indent3-ka1">The set of child strings shown in <a href="#tab4.2">Table 4.2</a> forms the starting point for generation 2; each string is a copy of a single parent in the first generation, two copies of string 1, one each of strings 2-9, and none of string 10. A new population generated by the roulette wheel is almost certain to contain multiple copies of some of the fitter strings, and be without copies of some of the less fit strings, because of the bias of the selection process towards the fitter strings.</p><p class="indent3-ka1">This bias is not marked because the difference in fitness between the best and worst strings is as yet quite small; as a result, the roulette wheel shows little discrimination in making the new population: poor strings and good strings are both likely to be selected. However, the discrimination increases as the calculation proceeds, and the difference in fitness between good and bad strings grows. To anticipate later results, although in population 1 the range of unsealed fitnesses is 0.0523 to 0.0227, by population 20 the range is 3.125 to 0.344, and in population 97, the range is from 9.09 to 0.299. By then, the roulette wheel is more than 30 times as likely to reproduce the best string as it<a id="page_74" class="page">Page 74, Genetic algorithms</a>is to reproduce the worst, and survival-of-the-fittest clearly has a dominant effect on the composition of the new population.</p><p class="indent3-ka1">A large range of fitness is broadly beneficial, since it encourages the proliferation of good solutions, and the discarding of poor solutions. Within a few generations of the start of the calculation, as the range of fitness grows, the best strings are being reliably reproduced from one generation to the next, while poor strings are being discarded with similar efficiency.</p><p class="indent3-ka1">Because the roulette wheel is biased towards fitter strings, the average fitness of the new population will generally exceed that of the parent population. This is progress of a sort, but in reality not much has been accomplished yet. There are no solutions in the new population that were not present in the first one, and we have yet to improve upon any of these initial, random, solutions. We need to find some method by which new high-quality strings can be generated.</p><h3 class="h3a"><b>Swapping genes: the crossover operator</b></h3><p class="noindent">The most fundamental role in the creation of good solutions is played by the crossover operator; this performs the GA equivalent of evolutionary mating.</p><p class="indent3-ka1">The mixing of genes that accompanies sexual reproduction ensures that biological offspring have characteristics derived from both parents. A particularly fortuitous combination of genes may lead to a child significantly better adapted to its environment than either of its parents &#x2013; a fitter individual. Because of the enhanced fitness that this child enjoys, it should in turn contribute its own descendants to the next generation, so that the favourable combination of genes will survive and, indeed, proliferate through succeeding generations, as less fit competitors are elbowed out of the population.</p><p class="indent3-ka1">The multiplication of fitter individuals at the expense of the less fit drives biological evolution; a parallel process pushes the GA towards good solutions.</p><p class="indent3-ka1">Two GA strings mate through the good offices of the crossover operator. This cuts a pair of randomly-chosen strings at some position and swaps the cut segments (<a href="#fig_4.11">Fig. 4.11</a>).</p><figure style="margin-left:-7em;margin-top:5em;" id="fig_4.11"><img src="../images/page74-1.jpg" alt="images"/><figcaption><b>Fig. 4.11</b> One-point crossover.</figcaption></figure><a id="page_75" class="page" style="width:70%;">Page 75, Genetic algorithms</a><p class="indent3-ka1">The crossover operator is applied to pairs of child strings chosen at random from those selected by the roulette wheel. In our example, child strings 1 and 3, which are</p><p class="indent" style="margin-top:1em;margin-left:2em;">{183,165, 313, 253, 294, 84} and {302, 105, 80, 45, 137, 97},</p><p class="noindentt">are chosen for crossover from the new population. A cut is made arbitrarily between positions 3 and 4, and the cut segments swapped to yield the new strings</p><p class="indent" style="margin-top:1em;margin-left:2em;">{183, 165, 313, 45, 137, 97} and {302, 105, 80, 253, 294, 84}</p><p class="indent3-ka1t">This is <b>one-point crossover</b>, in which a single cut is made; <b>two-point crossover</b> (<a href="#fig_4.12">Fig. 4.12</a>) is also widely-used (though we shall not use it in our example), and other crossover operators may be used in special situations when simple one- or two-point crossover might yield invalid strings, or are inappropriate for some other reason.</p><figure style="margin-left:-7em;" id="fig_4.12"><img src="../images/page75-1.jpg" alt="images"/><figcaption><b>Fig. 4.12</b> Two-point crossover.</figcaption></figure><aside class="abc" style="margin-top:-11.5em;" epub:type="sidebar"><p class="noindent2">Two-point crossover between positions 2 and 4 of the two strings shown in the text would yield the two new strings:</p><p class="noindent2" style="margin-top:1.5em;">{183, 105, 80, 45, 294, 84} and {302, 165, 313, 253, 137, 97}.</p></aside><p class="indent3-ka1t">The cut-and-pasting performed by crossover has the effect of shuffling string segments so that strings in the new population inherit characteristics from two members of the old one. If both parents were fit strings, then by analogy with biological systems, one or both of the offspring stand a good chance of being fitter than either parent.</p><aside class="abc" style="margin-top:-3em;" epub:type="sidebar"><p class="noindent2">Inheritance by a child string of high-quality segments from two parents is a second factor encouraging the development of high-quality strings in the population.</p></aside><p class="indent3-ka1">Crossover is used on most (sometimes all) members of the new population, and in each case the partners to be crossed and the position of the crossover cut are selected randomly. The two strings that result from crossover take the places in the population of the strings from which they were derived. Crossover is not simply a mechanical attempt to reproduce another of the steps of evolution, but, as we shall see, is a powerful way of increasing the overall fitness of the population.</p><p class="noindent">&#160;</p><h3 class="h3"><b>Mutation</b></h3><p class="noindent">In nature, mutations to chromosomes sometimes occur. Strings in the GA may also mutate; this is done by making a random change at an arbitrarily-chosen position in a string. When a string in the sample calculation is mutated, a random angle is replaced by a randomly-selected new one,<a id="page_76" class="page">Page 76, Genetic algorithms</a>within the permissible range of 0 to 359&#x00B0;. For reasons discussed in <a href="#sec_4.6">Section 4.6</a>, mutation is applied only infrequently, and in our calculation it occurs at the rate of one mutation per generation. Mutation rates are typically around 1 per 1000 genes, though higher rates are often used for relatively simple problems like the present one. The mutation operator working on the new population selects for mutation the string {318, 232, 324, 302, 249, 119}, which had been placed into population 2 by the reproduction operator, but not crossed with another string, and transforms it into {318, 232, 324, 302, 249, 43}.</p><aside class="abc" style="margin-top:-10.5em;" epub:type="sidebar"><p class="noindent2">In biological systems most mutations are harmful or inconsequential; only rarely does a random mutation yield a significantly fitter individual. However, the population size in natural systems is usually large enough that substantial diversity across the population already exists; biological mating tends to reinforce that diversity and minimizes the chances of stagnation. In the GA by contrast, the population is small, and very vulnerable to loss of diversity; the mutation operator then has an important role to play in preventing the population from becoming too homogeneous.</p></aside><p class="indent3-ka1">The main function of mutation is, through the introduction of new genetic material, to prevent the population from stagnating. Nevertheless, increasing homogeneity in the population, which mutation helps to limit, is an inevitable result of the success of the calculation. As the calculation proceeds, unfit strings are gradually discarded by the reproduction operator, and fit strings proliferate. The cut-and-pasting of crossover tends to disrupt strings, and reduce the chance that a single string will take over the population entirely, but the population still progressively loses variety as inbreeding (crossover between almost identical strings) grows.</p><p class="indent3-ka1">If this loss of variety becomes severe, convergence slows, and in the absence of mutation the algorithm may become trapped at a sub-optimal solution and be unable to escape. The introduction of random mutations at a small rate continually injects diversity into the population and prevents the reproduction operator from filling the population with large numbers of good, but sub-optimal strings.</p><p class="indent3-ka1">After reproduction, crossover, and mutation, the members of generation 2 are as shown in <a href="#tab4.3">Table 4.3</a>.</p><h3 class="h3a"><b>The next generation</b></h3><p class="noindent">The new population is now complete, and the algorithm returns to step 2. The interaction energy for each new string is calculated and, from these, the new fitnesses are found; these are shown in <a href="#tab4.3">Table 4.3</a>. As the table shows, the average fitness has risen, and the best string is better than the best in the first population; better solutions have arisen following the evolution-like manipulations described above.</p><p class="indent3-ka1">But we should be cautious about congratulating the algorithm on this improvement: perhaps the higher fitnesses are mere chance. After all, roulette wheel selection preferentially selects high-fitness strings as the starting point for the new generation, so the average fitness should improve, provided that the disruption caused by crossover and mutation is not too great. Furthermore, the population is small, and the initial random population might have been a peculiarly unfit bunch, from which the mix-and-match of crossover just happened to generate a fitter best string. Does the improvement in fitness really arise from the manipulations of the GA itself?</p><a id="page_77" class="page" style="width:70%;">Page 77, Genetic algorithms</a><p class="tabcap" id="tab4.3" style="margin-bottom:-1em;"><b>Table 4.3</b> The strings in generation 2.</p><figure style="margin-left:-12em;"><img src="../images/page77-1.jpg" alt="images"/></figure><p class="noindent">&#160;</p><p class="indent3-ka1t">The way to find out is to run the algorithm a little longer. After ten generations (<a href="#tab4.4">Table 4.4</a>) the average fitness is 0.4728, and that of the best string is 0.7825. Even the worst string now has a fitness that exceeds that of the best string in generation 1. The strings bear little resemblance to their ancestors in the first generation &#x2013; nine cycles of cut-and-pasting by the crossover operator have seen to that &#x2013; but there can be no doubt that fitter strings are being created. As <a href="#fig_4.13">Fig. 4.13</a> shows, as generations pass there is a steady move towards good &#x2013; and eventually optimum &#x2013; solutions.</p><p class="indent3-ka1">Evolution really does solve chemical problems. But how does it do it?</p><figure style="margin-left:-7em;" id="fig_4.13"><a id="page_78" class="page" style="width:84%;">Page 78, Genetic algorithms</a><img src="../images/page78-1.jpg" alt="images"/><figcaption><b>Fig. 4.13</b> The variation of energy with generation number.</figcaption></figure><p class="noindent">&#160;</p><p class="tabcap" id="tab4.4" style="margin-bottom:-1em;"><b>Table 4.4</b> The strings in generation 10.</p><figure style="margin-left:-11.5em;"><img src="../images/page78-2.jpg" alt="images"/></figure><aside class="abc" style="margin-top:-20em;" epub:type="sidebar"><p class="noindent2">Note how much the homogeneity of the population has increased by generation 10, as the algorithm starts to &#x2018;home in on&#x2019; a good answer.</p></aside></section><section epub:type="chapter" id="sec_4.5"><a id="page_79" class="page" style="width:70%;">Page 79, Genetic algorithms</a><h2 class="h2"><b>4.5&#160;&#160;Why does the GA work?</b></h2><p class="indent3-ka1">It is the aim of the GA to derive strings with the highest possible fitness. In this problem the fittest strings are those that contain several &#x2018;good&#x2019; dihedral angles in the sense that we defined earlier.</p><aside class="abc" style="margin-top:-5em;" epub:type="sidebar"><p class="tabcap"><a id="tab4.5"></a><b>Table 4.5</b> The proliferation of good angles.</p><table class="width100tb"><tr><td style="vertical-align:top;" class="borbw50"><p class="tabled">Generation</p></td><td style="vertical-align:top;" class="borbw50"><p class="tableb">No. of &#x2018;good&#x2019; angles in the population</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec2">1</p></td><td style="vertical-align:top;"><p class="tablec2">&#160;4</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec2">2</p></td><td style="vertical-align:top;"><p class="tablec2">&#160;5</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec2">5</p></td><td style="vertical-align:top;"><p class="tablec2">14</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec2">10</p></td><td style="vertical-align:top;"><p class="tablec2">20</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec2">20</p></td><td style="vertical-align:top;"><p class="tablec2">39</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec2">50</p></td><td style="vertical-align:top;"><p class="tablec2">49</p></td></tr><tr><td style="vertical-align:top;"><p class="tablec1">&#160;100</p></td><td style="vertical-align:top;"><p class="tablec2">59</p></td></tr></table></aside><p class="indent3-ka1">Strings which contain one or more good angles should have above-average fitness (though, particularly in the early generations, the beneficial effect of these angles will sometimes be cancelled out by the presence of some particularly poor angles in the same string). When the reproduction operator selects strings for the next generation, it preferentially picks high fitness strings, and may make several copies of the best of them. It was the presence of good angles in these strings that made them fit, so <i>the effect of the reproduction operator is to cause proliferation not just of fit strings, but also of the good angles within them</i>. This effect is illustrated in <a href="#tab4.5">Table 4.5</a> which shows how the number of good angles in the population grows as the algorithm runs.</p><p class="indent3-ka1">The crossover operator also promotes the growth of good angles. Consider the following two strings, both of which are members of generation 1:</p><p class="indent" style="margin-top:1em;margin-left:1em;">{300, 297, 72, 318, 344, 196} and {203, 103, 343, 70,180, 51}.</p><p class="indent3-ka1t">Each contains a single good angle, shown in bold face. Each string was reproduced once at the end of the first generation by the reproduction operator, and the two child strings were then brought together and combined by crossover. The application of this operator, cutting between positions 3 and 4, brings together the two good angles in one new string,</p><p class="centerd2" style="margin-top:1em;margin-left:13em;">{300,297,72,70,180,51}.</p><p class="indent3-ka1t">This string has a fitness greater than that of either parent because of the presence of two good angles, and this will enhance its ability to survive and proliferate in further generations.</p><aside class="abc" style="margin-top:-4em;" epub:type="sidebar"><p class="noindent2">The second string generated by crossover of the two shown in the main text is {203, 103, 343, 318, 344, 196}. This string contains no good angles, so should have low fitness. This is indeed the case, and it fails to be copied by the reproduction operator at the end of generation 2 and is lost from the population.</p></aside><p class="indent3-ka1">The good string, by virtue of its superior fitness, is likely to be selected by the reproduction operator when the time comes to build population 3; in fact in the calculation used in this illustration, the string was copied three times by the roulette wheel. Whereas in generation 1 there was just a single copy of each of the good angles &#x03B1;<sub>1</sub> =300 and &#x03B1;<sub>5</sub> =180, by generation 3 there are three copies of each. Through crossover, either or both of these angles may be spliced into other strings, raising the fitness of these strings in the process. The combined efforts of the reproduction and crossover operators are compounding the number of good angles in the population, even at this early stage.</p><p class="indent3-ka1">The two good angles represent part of an optimum solution. A string containing these two angles has, in effect, learnt a little about what a good solution looks like, and is rewarded for this useful knowledge with high fitness. The high fitness ensures that what has been learnt does not die out, but gets passed into subsequent generations. In this way knowledge is copied<a id="page_80" class="page">Page 80, Genetic algorithms</a>by reproduction from one generation to the next, and gradually infects other members of the population through crossover. Learning is spreading through the population.</p><h3 class="h3a"><b>Schemata</b></h3><aside class="abc" style="margin-top:1em;" epub:type="sidebar"><p class="noindent2">Early in the calculation, good schemata, that is schemata which confer high fitness on strings that contain them, will be few in number, and short.</p></aside><p class="noindent">We can think of this pair of good angles as a sort of &#x2018;building block&#x2019;. It is the job of the GA to generate such building blocks and shuffle them among strings, gradually assembling them into solutions of higher and higher quality. Though good building-blocks may be widely dispersed in the population, the evolutionary manipulations of the GA will frequently bring together two or more building blocks in a single string. When this happens, the superior fitness of the string thus created will make it likely that this superior solution is not lost, but passed from one generation to the next until displaced by yet better solutions.</p><p class="indent3-ka1">Building blocks are a central part of the GA, and their proliferation is the fundamental mechanism by which the GA assembles good solutions. Indeed, the building blocks are so important that they are given a special name, the <b>schemata</b> (singular <b>schema</b>). Although much of GA theory can be understood in non-mathematical terms, one equation which describes how schemata proliferate in a population occupies a central position in GA work, and an understanding of its derivation will help to clarify why the GA is such a successful searching algorithm.</p></section><p class="noindent">&#160;</p><section epub:type="chapter" id="sec_4.6"><h2 class="h2"><b>4.6&#160;&#160;The schema theorem</b></h2><p class="noindent">A schema is a <b>pattern-matching template</b>. This is a string in which certain fixed positions contain numbers, while all other positions are occupied by an asterisk, which is a &#x2018;don&#x2019;t care&#x2019; symbol. An example of a schema for the conformer problem is {300, *, *, *, 180, *}. A string is said to &#x2018;contain a given schema&#x2019; if the numbers in all the fixed positions in the schema match exactly the numbers in the equivalent positions in the string.</p><aside class="abc" style="margin-top:-1em;" epub:type="sidebar"><figure style="margin-left:0em;" id="fig_4.14"><img src="../images/page80-1.jpg" alt="images"/><figcaption class="noindent2" style="margin-top:1em;"><b>Fig. 4.14</b> Two strings with a schema in common.</figcaption></figure></aside><p class="indent3-ka1">Values in the string in positions in which the schema has an asterisk are of no consequence. For example, the strings {300, 297, 72, 70, 180, 51} and {300, 105, 78, 70, 180, 307} contain the schema shown above, but the strings {297, 300, 70, 72, 180, 51} and {300, 297, 72, 180, 70, 51} do not (<a href="#fig_4.14">Fig. 4.14</a>).</p><p class="indent3-ka1">Schemata multiply under the influence of the reproduction and crossover operators as the GA runs; the <b>schema theorem</b> predicts the rate at which this will occur.</p><p class="indent3-ka1">Reproduction copies strings with a probability proportional to their fitness. Each time the roulette wheel is spun, the probability that string <i>i</i> is copied by the reproduction operator is <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>/</mo><mtext>&#x2009;</mtext><mstyle><munder><mo>&#x2211;</mo><mi>i</mi></munder></mstyle><msub><mi>f</mi><mi>i</mi></msub></mrow></math>In a population of <i>n</i> strings, the operator <a id="page_81" class="page">Page 81, Genetic algorithms</a>will be called <i>n</i> times per generation and the expected number of copies of string <i>i</i> in the new population will therefore be</p><p class="eqn"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>m</mi><mi>i</mi></msub><mo>(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>)</mo><mtext>&#x2009;</mtext><mo>=</mo><mtext>&#x2009;</mtext><mi>n</mi><mtext>&#x2009;</mtext><msub><mi>f</mi><mi>i</mi></msub><mo>/</mo><munder><mi>&#x03A3;</mi><mi>i</mi></munder><msub><mi>f</mi><mi>i</mi></msub><mtext>&#x2009;</mtext></mrow></math><span class="no">(4.2)</span></p><aside class="abc" style="margin-top:-2em;" epub:type="sidebar"><p class="noindent2">You may recognize that <i>m<sub>i</sub></i>(<i>t</i>+1) is the scaled fitness of string <i>i</i>.</p></aside><p class="noindent">in which <i>m<sub>i</sub></i>(<i>t</i>+1) is the number of copies of string <i>i</i> in generation <i>t</i>+1 if the string has fitness <i>f<sub>i</sub></i> in generation <i>t</i>.</p><p class="indent3-ka1">If a schema <i>H</i> were present only in string <i>i</i>, this equation would tell us how many copies of the schema should occur in the new population. However, one schema may be contained in several different strings, each with its own fitness. The expected number of copies of that schema in the next generation is thus given by</p><p class="eqn"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>m</mi><mi>i</mi></msub><mrow><mo>(</mo><mrow><mi>H</mi><mo>,</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>=</mo><mtext>&#x2009;</mtext><mi>m</mi><mrow><mo>(</mo><mrow><mi>H</mi><mo>,</mo><mi>t</mi></mrow><mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>.</mo><mi>n</mi><mtext>&#x2009;</mtext><mo>.</mo><msub><mi>f</mi><mi>i</mi></msub><mrow><mo>(</mo><mi>H</mi><mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>/</mo><munder><mstyle><mi>&#x03A3;</mi></mstyle><mi>i</mi></munder><msub><mi>f</mi><mi>i</mi></msub></mrow></math><span class="no">(4.3)</span></p><p class="noindent">in which <i>f<sub>i</sub></i>(<i>H</i>) is the average fitness of all strings containing the schema. Making the replacement</p><p class="eqn"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mmultiscripts><mi>f</mi><mprescripts/><none/><mo>&#x2212;</mo></mmultiscripts><mtext>&#x2009;</mtext><mo>=</mo><mtext>&#x2009;</mtext><mstyle><munderover><mo>&#x2211;</mo><mi>i</mi><mrow></mrow></munderover><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow></mstyle><mo>/</mo><mi>n</mi></mrow></math><span class="no">(4.4)</span></p><p class="noindent">we can rewrite eqn (3) as:</p><p class="eqn" id="eqn_4.5"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msub><mi>m</mi><mi>i</mi></msub><mrow><mo>(</mo><mrow><mi>H</mi><mo>,</mo><mtext>&#x2009;</mtext><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>=</mo><mtext>&#x2009;</mtext><msub><mi>m</mi><mi>i</mi></msub><mrow><mo>(</mo><mrow><mi>H</mi><mo>,</mo><mi>t</mi></mrow><mo>)</mo></mrow><mo>.</mo><mtext>&#x2009;</mtext><msub><mi>f</mi><mi>i</mi></msub><mrow><mo>(</mo><mi>H</mi><mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>/</mo><mmultiscripts><mi>f</mi><mprescripts/><none/><mo>&#x2212;</mo></mmultiscripts></mrow></math><span class="no">(4.5)</span></p><aside class="abc" style="margin-top:-3em;" epub:type="sidebar"><p class="noindent2"><a href="#eqn_4.5">Equation (4.5)</a> defines mathematically how a fit schema will multiply, but it also tells us that a schema which confers a fitness <i>disadvantage</i> to strings that contain it will tend to be removed from the population, since the ratio of the average string fitness of strings that contain the schema to the average population fitness will be less than one.</p></aside><p class="indent3-ka1t">The rate at which a good schema proliferates in the population therefore depends upon the ratio of the average fitness of the strings which contain the schema to the average fitness of the population as a whole. Thus, a schema which confers a large fitness benefit upon any string that contains it will multiply rapidly in the population.</p><p class="indent3-ka1">It can be shown that, if a schema <i>H</i> is always fitter than the average fitness by a fixed proportion &#x03B2;, then the number of examples of the schema in the population grows according to the equation:</p><p class="eqn" id="eqn_4.6"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>m</mi><mrow><mo>(</mo><mrow><mi>H</mi><mo>,</mo><mi>t</mi></mrow><mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>=</mo><mtext>&#x2009;</mtext><mi>m</mi><mrow><mo>(</mo><mrow><mi>H</mi><mo>,</mo><mn>0</mn></mrow><mo>)</mo></mrow><mo>&#x22C5;</mo><mtext>&#x2009;</mtext><msup><mrow><mrow><mo>(</mo><mrow><mn>1</mn><mo>+</mo><mi>&#x03B2;</mi></mrow><mo>)</mo></mrow></mrow><mi>t</mi></msup></mrow></math><span class="no">(4.6)</span></p><aside class="abc" style="margin-top:1.5em;" epub:type="sidebar"><p class="noindent2">The importance of implicit parallelism, introduced in this paragraph, to the success of the GA cannot be over-stated. The evolutionary basis of the algorithm gives it the power to search massive surfaces; implicit parallelism explains how it is able to do this in a reasonable time.</p></aside><p class="indent3-ka1t">This indicates that the number of copies of a consistently above-average schema rises geometrically in a population, while below average schemata (&#x03B2; &lt; 0) will be removed from the population at a geometrically diminishing rate. This growth in numbers of high-quality schemata <i>takes place for all schemata simultaneously</i>. In any population of significant size, there will be many beneficial schemata, and they will <i>all</i> grow in number according to <a href="#eqn_4.6">eqn (4.6)</a>, as long as the fitness of the strings that contain them remains above the average fitness. It can in fact be shown that the number of schemata processed usefully each generation is of the order of <i>n</i><sup>3</sup> for a population of <i>n</i> strings. Since typical GA populations consist of between 25 and 100 strings, the number of schemata processed per generation is very large, and this has<a id="page_82" class="page">Page 82, Genetic algorithms</a>the potential to yield rapid improvements in the average fitness of the population. This simultaneous processing of many schemata is known as <b>implicit parallelism</b>, and is a crucial reason why the algorithm can successfully search even massive surfaces.</p><p class="indent3-ka1">However, this growth of schemata does not take place unimpeded, since all schemata risk being cut by the crossover operator or destroyed by mutation. Our calculation of the rate at which schemata multiply must take these effects into account.</p><p class="indent3-ka1">Crossover will not affect all schemata with equal probability. The crossover operator is most likely to damage those schemata in which the distance between the fixed positions is large. For example, the string {300, 297, 72, 70, 180, 51} contains (amongst many others) the schemata <i>H</i><sub>1</sub> = {300, *, *, *, 180, *} and <i>H</i><sub>2</sub> = {*, *, *, *, 180, 51}. Under crossover, schema <i>H</i><sub>1</sub> will be disrupted if a cut is made immediately before positions 2, 3, 4, or 5, while schema <i>H</i><sub>2</sub> will only be disrupted by a cut immediately before position 6. Schemata in which all the fixed positions are close together are clearly more likely to survive crossover than schemata in which the fixed positions are far apart.</p><p class="indent3-ka1">To quantify this, we introduce the <b>defining length</b> of a schema, written &#x03B4;(<i>H</i>), which is the distance between the first and last fixed position; we will also shortly need the <b>order</b> of a schema, written o(<i>H</i>), which is the number of fixed positions. Thus the two schema above both have an order of 2: the first has a defining length of 4 and the second a defining length of 1.</p><p class="indent3-ka1">Schema <i>H</i><sub>1</sub> is destroyed by crossover for four different choices of cut position and survives for one choice; the probability that it will survive crossover is thus 1/5. Schema <i>H</i><sub>2</sub> is destroyed by one choice of crossover position, but survives if the cut is made in any of the remaining four positions; its probability of survival is 4/5. In general, the probability that a schema will survive crossover is</p><p class="eqn" style="margin-top:1em;"><i>p</i> = 1 &#x2212; &#x03B4;(<i>H</i>)/(<i>l</i> &#x2212; 1)<span class="no">(4.7)</span></p><p class="noindentt">in which <i>l</i> is the length of the string.</p><p class="indent3-ka1">There may be strings in the new population to which crossover is not applied. Obviously all schema in such strings survive the crossover stage in the formation of the new population, so if the probability of crossover is p<sub>c</sub>, the chance of a schema surviving is</p><p class="eqn" id="eqn_4.8" style="margin-top:1em;"><i>p</i> &#x2265; 1 &#x2212; <i>p</i><sub>c</sub> &#x03B4;(<i>H</i>)/(<i>l</i> &#x2212; 1)<span class="no">(4.8)</span></p><p class="indent3-ka1t">We have introduced a &#x2265; sign into this expression, since, even if the crossover operator splits a schema, there is a chance that the schema might be re-created if its crossover partner has the same values in the fixed positions as the cut portion. For example, a cut of the string {300, 297, 72, 70, 180, 51} between position 3 and 4 will destroy the schema {300, *, *, *, 180, *}, but if crossover takes place with the string {107, 4, 11, 213, 180, 72}, the schema is re-created in the new string {300, 297, 72, 213, 180, 72}.</p><a id="page_83" class="page" style="width:70%;">Page 83, Genetic algorithms</a><p class="indent3-ka1">Combining <a href="#eqn_4.8">eqn (4.8)</a> with our expression for the rate at which reproduction causes schema to proliferate, we have</p><p class="eqn" style="margin-top:1em;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow> <msub><mi>m</mi><mi>i</mi></msub> <mrow><mo>(</mo><mrow> <mi>H</mi><mo>,</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow> <mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>&#x2265;</mo><mtext>&#x2009;</mtext><msub><mi>m</mi><mi>i</mi></msub> <mrow><mo>(</mo><mrow> <mi>H</mi><mo>,</mo><mi>t</mi></mrow> <mo>)</mo></mrow><mo>.</mo><mtext>&#x2009;</mtext><msub><mi>f</mi><mi>i</mi></msub> <mrow><mo>(</mo><mi>H</mi> <mo>)</mo></mrow><mo>.</mo><mtext>&#x2009;</mtext><mo>[</mo><mn>1</mn><mo>&#x2212;</mo><msub><mi>p</mi><mi>c</mi></msub> <mtext>&#x2009;</mtext><mi>&#x03B4;</mi><mrow><mo>(</mo><mi>H</mi> <mo>)</mo></mrow><mo>/</mo><mrow><mo>(</mo><mrow> <mi>l</mi><mo>&#x2212;</mo><mn>1</mn></mrow> <mo>)</mo></mrow><mo>]</mo><msup><mo>/</mo><mo>&#x2212;</mo></msup> <mi>f</mi><mtext>&#x2009;</mtext><mrow><mo></mo></mrow></mrow></math><span class="no">(4.9)</span></p><p class="indent3-ka1t">This equation shows that schema of low defining length contained in strings of high fitness are those which will multiply most rapidly.</p><p class="indent3-ka1">The final GA operator is mutation. This destroys schemata at a rate which depends upon the probability of mutation per position in a string, <i>p</i><sub>m</sub>, and the number of fixed positions in the schema (a schema is unaffected by mutation in one of its &#x2018;don&#x2019;t care&#x2019; positions). The chance that a single fixed position will survive mutation is (1&#x2013;<i>p</i><sub>m</sub>). For the schema as a whole to survive, all o(<i>H</i>) fixed positions must individually survive, and the chance that this will happen is (1&#x2013;<i>p</i><sub>m</sub>)<sup>o(<i>H</i>)</sup>. The term <i>p</i><sub>m</sub> is always small to guarantee that the disruptive effect of mutation does not destroy good schemata at a significant rate, so this can be approximated to 1&#x2013;o(<i>H</i>).<i>p</i><sub>m</sub>. Thus the final expression for the rate at which schemata are reproduced is</p><p class="eqn" style="margin-top:1em;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow> <msub><mi>m</mi><mi>i</mi></msub> <mrow><mo>(</mo><mrow> <mi>H</mi><mo>,</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow> <mo>)</mo></mrow><mtext>&#x2009;</mtext><mo>&#x2265;</mo><mtext>&#x2009;</mtext><msub><mi>m</mi><mi>i</mi></msub> <mrow><mo>(</mo><mrow> <mi>H</mi><mo>,</mo><mi>t</mi></mrow> <mo>)</mo></mrow><mo>.</mo><mtext>&#x2009;</mtext><msub><mi>f</mi><mi>i</mi></msub> <mrow><mo>(</mo><mi>H</mi> <mo>)</mo></mrow><mo>.</mo><mtext>&#x2009;</mtext><mo>[</mo><mn>1</mn><mo>&#x2212;</mo><msub><mi>p</mi><mi>c</mi></msub> <mtext>&#x2009;</mtext><mi>&#x03B4;</mi><mrow><mo>(</mo><mi>H</mi> <mo>)</mo></mrow><mo>/</mo><mrow><mo>(</mo><mrow> <mi>l</mi><mo>&#x2212;</mo><mn>1</mn></mrow> <mo>)</mo></mrow><mo>&#x2212;</mo><mtext>o</mtext><mrow><mo>(</mo><mi>H</mi> <mo>)</mo></mrow><msub><mi>p</mi><mi>m</mi></msub> <mo>]</mo><msup><mo>/</mo><mo>&#x2212;</mo></msup> <mi>f</mi><mtext>&#x2009;</mtext><mrow><mo></mo></mrow></mrow></math><span class="no">(4.10)</span></p><p class="indent3-ka1t">This equation is known as the <b>schema theorem</b>, or the <b>fundamental theorem of genetic algorithms</b>. This is rather a grand title, but the success of the GA relies upon the proliferation of good schemata, and this equation tells us how rapidly this will occur; it is therefore a central equation in genetic algorithms.</p></section><section epub:type="chapter" id="sec_4.7"><p class="noindent">&#160;</p><h2 class="h2"><b>4.7&#160;&#160;Applications of the GA</b></h2><p class="noindentt">Problems for which the power of the GA is useful are quite well defined; we can expect them to show three particular features:</p><p class="indent3-ka1t"><img src="../images/page9-1.jpg" alt="images"/>&#160;&#160;<i>The problem presents a significant challenge to conventional methods of solution</i>.</p><p class="indent3-ka1">We have seen earlier that AI methods are not intended for use in simple problems, and this remains true for the GA, which becomes progressively more valuable as the scale of the problem grows, because of implicit parallelism. GA problems must therefore be difficult to solve; indeed, for some very large scale problems it appears that the GA is the only realistic method of attack presently available.</p><p class="indent3-ka1t"><img src="../images/page9-1.jpg" alt="images"/>&#160;&#160;<i>It must be possible to cast the solutions to a problem in the form of a string which the GA can manipulate</i>.</p><p class="indent3-ka1">For some problems this cannot be done, and then the GA cannot be used. However, the definition of a &#x2018;string&#x2019; is not quite as restricted as our discussion so far has suggested: recent work on the application of GAs to the dispersal of<a id="page_84" class="page">Page 84, Genetic algorithms</a>pollution suggests that for some problems, though a string may be inappropriate, a matrix description of the solutions may be used. This matrix is then manipulated in the usual way by the crossover, reproduction, and mutation operators.</p><p class="indent3-ka1t"><img src="../images/page9-1.jpg" alt="images"/>&#160;&#160;<i>Since the GA works by manipulating schemata</i>, <i>the GA will be unable to tackle a problem successfully unless a solution can be assembled by bolting together segments of strings</i>.</p><p class="indent3-ka1">Suppose the &#x2018;correct&#x2019; solution to a problem is coded by the string {&#x03B1;<sub>1</sub>, &#x03B1;<sub>2</sub>, &#x03B1;<sub>3</sub>, &#x03B1;<sub>4</sub>, &#x03B4;<sub>5</sub>, &#x03B4;<sub>6</sub>, &#x03B4;<sub>7</sub>). Strings containing schemata such as {&#x03B1;<sub>1</sub>, &#x03B1;<sub>2</sub>, &#x03B1;<sub>3</sub>, *, *, *, *}, or {*, *, *, *, &#x03B4;<sub>5</sub>, *, &#x03B4;<sub>7</sub>}, or {*, *, *, &#x03B1;<sub>4</sub>, &#x03B4;<sub>5</sub>, *, *} must generally have higher fitness than randomly-chosen strings, or the GA will not know how to select strings that contain good schemata.</p><p class="indent3-ka1">These requirements &#x2013; that the problem be complex, that solutions be codable in string form, and that it be possible to build solutions by bolting together good sub-strings &#x2013; inevitably impose some restrictions on the range of problems to which the GA can be applied. Despite this, there are numerous problems in which the GA can be useful, and if a problem can be cast in this form, it may produce solutions of a quality and at a speed that is unattainable through any other current method.</p><p class="indent3-ka1">We have already met the use of the GA in conformational analysis through our sample problem. This illustrative problem has been scaled up by many workers and the GA is now used to tackle the much more demanding protein-folding problem with some success. We shall illustrate the application of the GA in science with a further pair of examples.</p><p class="noindent">&#160;</p><h3 class="h3"><b>Optimization of synthetic routes in organic chemistry</b></h3><p class="noindentt">Chemists need to synthesize chemicals cheaply, efficiently and from readily-available precursors. The synthetic route to a complicated organic molecule is at present almost always devised by a human, but computer programs, whose purpose is to propose suitable synthetic routes to a desired product, are becoming more powerful and widely-used.</p><p class="indent3-ka1">The choice of a suitable route for a synthesis of three or four steps is often a fairly routine matter, but if ten or twelve synthetic steps are required, much depends upon the experience of the chemist in the development of a high-yield route. There are probably millions of possible routes that use known synthetic steps, since at each stage there may be scores of reactions that each intermediate might undergo (<a href="#fig_4.15">Fig. 4.15</a>).</p><figure style="margin-left:-8em;" id="fig_4.15"><a id="page_85" class="page" style="width:86%;">Page 85, Genetic algorithms</a><img src="../images/page85-1.jpg" alt="images"/><figcaption><b>Fig. 4.15</b> An illustration of synthetic routes in organic chemistry.</figcaption></figure><p class="indent3-ka1t"><a href="#fig_4.15">Figure 4.15</a> is reminiscent of the chess-playing problem discussed in <a href="Chapter01.xhtml#Ch01">Chapter 1</a>, and this is an example of a scientific problem which shows combinatorial explosion. Each GA string is chosen to represent a possible synthetic route to transform precursor <i>A</i><sub>n</sub> into the desired product. In this instance, while simple one-point crossover is a suitable mating operator, not every string can be validly crossed with every other string, since two strings can be crossed only when both have produced the same intermediate (<a href="#fig_4.16">Fig. 4.16</a>).</p><figure style="margin-left:-8em;" id="fig_4.16"><img src="../images/page85-2.jpg" alt="images"/><figcaption><b>Fig. 4.16</b> A valid string crossover for the synthetic routes problem.</figcaption></figure><p class="indent3-ka1t">Applications of this sort show great potential in combination with organic synthesis expert systems.</p><p class="noindent">&#160;</p><h3 class="h3"><b>Flowshop scheduling</b></h3><p class="noindentt">In the industrial synthesis of chemicals, manufacturers look to benefit from economies of scale. However if a chemical plant is devoted to the production of a single high-value product such as a pharmaceutical or paint dye, high-volume production can be self-defeating if the chemical can be sold in only small quantities.</p><p class="indent3-ka1">When synthesizing such chemicals, it is common to operate a &#x2018;chemical flowshop&#x2019; (<a href="#fig_4.17">Fig. 4.17</a>), in which different chemicals are synthesized within a single installation by passing the appropriate precursors into an array of reactors, dryers etc. whose configuration remains unchanged while different materials are produced.</p><figure style="margin-left:0em;width:70%;" id="fig_4.17"><a id="page_86" class="page" style="width:85%;">Page 86, Genetic algorithms</a><img src="../images/page86-1.jpg" alt="images"/><figcaption style="margin-left:0em;width:100%;"><b>Fig. 4.17</b> A chemical flowshop. Different products can be synthesized in a single set of reactors by feeding in the appropriate precursors.</figcaption></figure><p class="indent3-ka1t">A prime difficulty with such an arrangement is that, if the plant manager does not choose the order in which products are made with care, the line can become temporarily blocked if reaction in one particular vessel continues while reaction in the preceding vessels is over (<a href="#fig_4.18">Fig. 4.18</a>); this has an obvious negative effect upon the efficiency of the flowshop.</p><p class="noindent">&#160;</p><figure style="margin-left:-8em;" id="fig_4.18"><img src="../images/page86-2.jpg" alt="images"/><figcaption><b>Fig. 4.18</b> A flowshop line containing a temporary block.</figcaption></figure><p class="indent3-ka1t">To minimize such blockages, it is important that chemicals be produced in an order such that intermediates can move in nearly &#x2018;lock-step&#x2019; fashion through the flowshop (<a href="#fig_4.19">Fig. 4.19</a>).</p><p class="noindent">&#160;</p><p class="noindent">&#160;</p><figure style="margin-left:-8em;" id="fig_4.19"><img src="../images/page86-3.jpg" alt="images"/><figcaption><b>Fig. 4.19</b> Chemicals passing through a flowshop in &#x2018;lock-step&#x2019; fashion.</figcaption></figure><p class="indent3-ka1t">If <i>n</i> chemicals are produced by the flowshop, the number of different orders in which those chemicals can be made is <i>n</i>!, so for a flowshop synthesizing 20 products, there are roughly 10<sup>18</sup> different orders; in only a small proportion of these will the chemicals move from vessel to vessel in a nearly lock-step fashion. Since it is not possible to evaluate how good each of<a id="page_87" class="page">Page 87, Genetic algorithms</a>these 10<sup>18</sup> orders is, some intelligent method must be used to find near-optimum orders.</p><p class="indent3-ka1">A GA string for this problem consists of the order in which chemicals enter the first reactor. For example, the string {4, 18, 2, 14, 17, &#x2026;} means that chemical 4 is the first to enter the flowshop; when processing of this chemical in the first reactor is finished, it moves to the second reactor, allowing chemical 18 to enter the line, and so on. We note both that the size of the problem is large (10<sup>18</sup> solutions), and that segments of strings can readily be interpreted in terms of schemata (corresponding to a sub-group of chemicals that move together through the flowshop in a partial lock-step fashion). Strings of this sort can readily be optimized using the GA and results from GA flowshop calculations show this to be a particularly powerful approach.</p></section><section epub:type="chapter" id="sec_4.8"><h2 class="h2"><b>4.8&#160;&#160;Improvements to the simple GA</b></h2><p class="noindentt">The sections above outline a basic GA, which is effective for a wide range of problems. However, the performance of the algorithm can be improved by various adjustments, whose object is to speed convergence or reduce the chance of convergence to a sub-optimum solution. In this section we consider two widely-used enhancements to the algorithm.</p><h3 class="h3a"><b>Stochastic remainder</b></h3><p class="indent3-ka1t">Although the roulette wheel mechanism biases the selection of strings towards the fittest, it may still fail to select the best string in a population for reproduction, which is clearly undesirable.</p><div class="border"><p class="boxtitlec" style="margin-top:1em;margin-bottom:1em;"><b>Stochastic remainder selection</b></p><p class="boxhang">1. Scale all strings so that the average fitness is 1.0</p><p class="boxhang">2. For every string with above average fitness, make a number of copies equal to the integer part of their fitness. Thus a string with a scaled fitness of 3.7 would have three copies placed into the next generation. The number of copies made is subtracted from the scaled fitness, so that all strings have a remainder &lt; 1.</p><p class="boxhang">3. Use a probablistic procedure to select strings to fill the remaining spaces in the population. Choose a string at random and generate a random number. If the random number is less than the remainder of the fitness, then (a) make a copy of the string, and (b) reduce the fitness remainder to zero to prevent further copies of the string being made; if the random number is greater than the remainder, choose another string.</p><p class="boxhang" style="margin-bottom:1em;">4. Continue until the total number of copies equals the population size.</p></div><aside class="abc" style="margin-top:-15em;" epub:type="sidebar"><p class="noindent2">This procedure ensures copies of the fittest strings will always be made into the next generation and can have a highly beneficial effect on the rate of convergence (<a href="#fig_4.20">Fig. 4.20</a>).</p></aside><p class="noindent"><a id="page_88" class="page">Page 88, Genetic algorithms</a>Stochastic remainder selection is a strategy designed to ensure that all above-average strings will place at least one child in the new population, without unduly damaging the probablistic nature of the selection procedure.</p><p class="indent3-ka1">The steps in stochastic remainder selection are shown above.</p><figure style="margin-left:-8em;" id="fig_4.20"><img src="../images/page88-1.jpg" alt="images"/><figcaption><b>Fig. 4.20</b> The beneficial effects of stochastic remainder selection.</figcaption></figure><p class="noindent">&#160;</p><p class="noindent">&#160;</p><h3 class="h3"><b>Elitism</b></h3><p class="noindentt">Stochastic remainder guarantees that every string with above-average fitness will be copied at least once into the new generation, but once there, it is still possible for those strings to be destroyed by crossover. An elite procedure ensures that the best string in the current population is never lost.</p><p class="indent3-ka1">One way of doing this, as a new population is being constructed, is to flag a copy of the fittest string and protect it from attack by crossover or mutation. If this strategy is combined with stochastic remainder to guarantee that the fittest string is always reproduced, the best fitness in the population can never decrease.</p><p class="indent3-ka1">A second elitist method permits any string in the new population, including the best one, to suffer crossover. When crossover is complete, the fitness of every string in the new population is determined. If none of the strings in the new population is as fit as the best in the old, one of the least fit strings in the new population is displaced by the best of the old. This is a rather more powerful strategy than the first; crossover of the fittest string is potentially more valuable than crossover involving any other string in the new population, so protecting this from crossover, as the first elitist method does, is sometimes counter-productive.</p><p class="indent3-ka1">Other techniques to enhance the progress of the GA may also be used, such as the retention of copies of good strings from earlier generations in a<a id="page_89" class="page">Page 89, Genetic algorithms</a>pool of &#x2018;useful genes&#x2019;; these are then occasionally re-inserted into the population. Good schemata may be discovered, but sometimes accidentally lost as the algorithm proceeds, even using an elitist strategy. By re-introducing a few of the best strings from earlier generations perhaps once every hundred generations, we need not wait for the algorithm to rediscover good genetic material, and there is less likelihood that the calculation will become trapped at sub-optimal solutions.</p><p class="indent3-ka1">These last few paragraphs seem to suggest that we can introduce additional or amended operators into the GA in what may appear to be an arbitrary fashion. Curiously, this is exactly the case: there is no fixed prescription according to which a GA must be run, though the basic operators of reproduction, crossover, and mutation always remain. Variables such as population size and crossover rate must be determined by the user, and there is further freedom to choose strategies such as stochastic remainder, or elitist selection. Both experience and experiment play a large part in the choice of productive strategies and suitable parameter values.</p><h3 class="h3a"><b>Postscript</b></h3><p class="noindentt">Our ability to analyse and interpret scientific data is being significantly extended through the use of AI methods; this book has been able to provide just a hint of their power (but enough, we hope, to encourage you to investigate some of them further). As experience in their use expands, new roles and uses for them are being found. Their use is still in its infancy, but AI techniques are destined to be of central importance in science within a few years. The time when scientists use computers not just as tools to help in the analysis of data, but as partners in the development of scientific laws and understanding has almost arrived.</p><h1 class="main1"><b>Further reading</b></h1><p class="noindente">Davis, L. (ed.) (1991). <i>Handbook of genetic algorithms</i>. Van Nostrand Reinhold, New York.</p><p class="noindente">Goldberg, D.E. (1989). <i>Genetic algorithms in search, optimisation and machine learning</i>. Addison-Wesley, Reading, Mass.</p><p class="noindente">Holland, J. (1975). <i>Adaptation in natural and artificial systems</i>. University of Michigan Press, Ann Arbor, MI.</p></section></section></body></html>