<?xml version="1.0" encoding="utf-8"?>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en" lang="en">
<head>
<meta charset="utf-8"/>
<title>Statistical mechanics</title>
<link rel="stylesheet" href="../styles/stylesheet.css" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<section epub:type="chapter" id="ch04">
<a id="page_46" class="page" style="width:70%;">Page 46, Statistical mechanics</a>
<h1 class="main">4<span class="space">&#160;</span>Statistical mechanics</h1>
<p class="noindent">&#160;</p>
<section epub:type="chapter" id="sec_4.1">
<h2 class="h2">4.1<span class="space">&#160;</span>Introduction</h2>
<p class="noindent">The validity of any computational model results from the successful reproduction and prediction of experimental observables. In the past this has tended more toward gas phase properties and <i>ab initio</i> calculations have, in fact, been more accurate in the prediction of spectroscopic frequencies than is sometimes possible by experiment. While serving the purpose of producing reliable structures of isolated molecules, it is clear that many more interesting systems would be amenable to study if calculations could be done in the solution phase. In addition to presenting the problem of how the solvent should be represented, there is the snag that experimentalists will usually produce numbers related to the free energy of a system, whereas the energy calculations considered so far give only potential energies, or at best enthalpies. To overcome this barrier the computational chemist must turn to the techniques of statistical mechanics. In this chapter we shall explore the methods for simulating &#x2018;real&#x2019; systems, and novel methods which can relate the calculated properties of our rather small, model systems to measured bulk properties.</p>
</section>
<section epub:type="chapter" id="sec_4.2">
<h2 class="h2">4.2<span class="space">&#160;</span>Solvation</h2>
<p class="noindent">That solvation plays an enormous role in the determining properties of molecules is self-evident. In physical-organic chemistry the effect of varying the solvent on reaction rates is well known. Also, the conformational equilibria existing in molecules can be changed by varying the medium, which has led to rules based upon favourable orientation of dipoles being dependent upon the dielectric constant of the solvent. In biological systems the major unsolved problem, that of how and why a protein adopts a particular conformation based simply on its sequence, could be reduced to the balance between differential solvation effects about hydrophilic and hydrophobic sidechains. Clearly the environment surrounding a molecule is very important. But how do we represent it?</p>
<aside class="abc" style="margin-top:-12.5em;" epub:type="sidebar">
<p class="noindent2">General methods to explore solvation are reviewed in Richards, W. G., King, P. M., and Reynolds, C. A. (1989). <i>Protein Engineering</i>, 2, 319&#x2013;327.</p>
</aside>
<p class="indent">The simplest way to take into account the influence of the solvent is to make the assumption that its major effect is to screen the electrostatic interactions in the solute. This can be accomplished by including the appropriate dielectric constant in the denominator of the electrostatic term in the molecular mechanics energy function. The calculation is then carried out on the isolated molecule. This method has clear limitations, the most obvious being that it takes no account of favourable solvent-solute interactions. In aqueous solution there could be a number of hydrogen bonds. By neglecting the van der Waals component, contraction of molecular volume can result as <a id="page_47" class="page">Page 47, Statistical mechanics</a>the molecule seeks to maximise favourable interactions. In the presence of solvent this tendency is balanced by van der Waals interactions between solvent and solute. It is obvious that, given the short-range nature of the function, its omission will result in distorted geometries. With protein systems the dielectric screening is not always adequate between charged sidechains on the surface. This can produce sidechains lying along the surface of the protein rather than protruding out into solvent.</p>
<p class="indent">A potentially much more powerful method is to consider the solute as being a volume of low dielectric constant embedded in an environment with a dielectric constant appropriate to the bulk solvent. The system can now be treated by the methods of classical electrostatics, allowing a more accurate estimation of the electrostatic energy. Systems of this type are governed by the Poisson-Boltzmann equation (Eqn. 4.1) and different, exact solutions exist if the molecule can be assumed to be spherical or cylindrical.</p>
<aside class="abc" style="margin-top:-8.5em;" epub:type="sidebar">
<p class="noindent2">The Poisson-Boltzmann equation is discussed in greater detail in Honig, B., Sharp, K., and Yang, A.-S. (1993). <i>J. Phys. Chem</i>., <b>97</b>, 1101&#x2013;1109.</p>
</aside>
<p class="fig1a" id="eq4.1"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mo>&#x2207;</mo><mtext>&#x03B5;(r)</mtext><mo>&#x2207;</mo><mi>&#x03D5;</mi><msup><mrow><mtext>(r)-&#x03B5;K</mtext></mrow><mtext>2</mtext></msup><mtext>sinh[</mtext><mi>&#x03D5;</mi><mtext>(r)]+4&#x03C0;</mtext><mi>q</mi><msup><mtext>&#x03C1;</mtext><mtext>f</mtext></msup><mtext>(r)/</mtext><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mtext>=0</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mtext>(4</mtext><mtext>.1)</mtext></mrow>
</semantics></math></p>
<p class="noindent">Here, &#x03D5;(r) is the electrostatic potential, <i>k</i><sub>B</sub> the Boltzmann constant, <i>T</i> the temperature, <i>q</i> the proton charge, &#x03B5; the dielectric constant and &#x03C1;<sup>f</sup> the fixed charge density. K<sup>2</sup> = <i>8&#x03C0;q<sup>2</sup>I/&#x03B5;&#x03BA;<sub>B</sub>T; I</i> is the ionic strength.</p>
<p class="indent">For a system such as a solvated molecule, the exact geometry of the cavity is not adequately approximated by the analytical solutions to <a href="#eq4.1">Eqn. 4.1</a>. However, if the atomic charges associated with the molecule are mapped onto a grid, and the grid points are considered to be inside or outside a dielectric boundary, it is possible to obtain numerical solutions to the problem. If the grid separation is close to atomic dimensions (typically l&#x00C5;) the results reflect, in some detail, the subtleties of the electrostatic potential. As an iterative solution is obtained there is polarization of the medium by the charges, since the electrostatic potential is calculated beyond the boundary of the molecule. This influences, in turn, the screening effect of the solvent on the solute charges.</p>
<aside class="abc" style="margin-top:-15em;" epub:type="sidebar">
<figure class="fig1" id="fig4_1">
<img src="../images/fig4_1.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.1</b>&#x00A0;&#x00A0;Energy components for the solvation of a charged molecule.</p>
</aside>
<p class="indent">Using the electrostatic potential grid the total electrostatic free energy &#x0394;<i>G</i><sup>a</sup> can be calculated by <a href="#eq4.2">Eqn. 4.2</a></p>
<p class="fig1a" id="eq4.2"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><msup><mi>G</mi><mi>a</mi></msup><mo>=</mo><mfrac><mtext>1</mtext><mtext>2</mtext></mfrac><mstyle displaystyle='true'><mo>&#x2211;</mo> <mrow><msub><mtext>q</mtext><mtext>i</mtext></msub><msup><mi>&#x03C6;</mi><mtext>a</mtext></msup><msub><mrow><mtext>(r</mtext></mrow><mtext>i</mtext></msub><mtext>)</mtext></mrow></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.2</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="indent">where <i>q</i><sub>i</sub> is charge at point a and &#x03D5;<sup>a</sup> is the induced electrostatic potential. Of course, this only gives the electrostatic component of the solvation energy. There is also a component representing the energy expended in creating a cavity in the solvent, and the concomitant reorganization of solvent around this cavity (see <a href="#fig4_1">Fig. 4.1</a>). The approach currently most favoured is to consider this contribution to be proportional to the solvent-accessible surface area (SA) of the solute molecule using atom-type dependent parameters &#x03C3;</p>
<p class="fig1a" id="eq4.3"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><msub><mi>G</mi><mrow><mtext>cav</mtext></mrow></msub><mo>=</mo><mstyle displaystyle='true'><mo>&#x2211;</mo> <mrow><msub><mi>&#x03C3;</mi><mtext>k</mtext></msub><mtext>SA</mtext></mrow></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.3</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">However, the calculation of both terms is necessary only if the absolute solvation energy is required (i.e., starting from the gas phase). When comparing the relative solvation energy changes on going from one solvent <a id="page_48" class="page">Page 48, Statistical mechanics</a>to another, it can be assumed that the cavity terms will be approximately equal and, therefore, cancel out.</p>
<p class="indent">Similar techniques have also been applied to molecular orbital methods by including continuum modified terms in the Fock matrix (see <a href="Chapter_02.xhtml#ch02">Chapter 2</a>). In this way the solvation energies and solvent modified electronic properties can be evaluated.</p>
<section epub:type="chapter" id="sec_4.2.1">
<h3 class="h3">Periodic boundary conditions</h3>
<p class="noindent">Often, a detailed description of solvent behaviour is the motivation for carrying out a simulation. The radial distribution function (rdf) of a solvent shows the probability of finding a neighbouring molecule <i>(m</i><sub>2</sub>) within a certain distance of <i>m</i><sub>1</sub> By averaging these pair distributions over the complete system i.e., considering each molecule in turn as <i>m</i><sub>1</sub> a clear picture of the gross solvent structure emerges (<a href="#fig4_2">Fig. 4.2</a>). If one wishes to observe the response of the rdf to a solute molecule, or the effect of a solute on solvent mobility, then continuum methods are no longer adequate. This kind of study requires the use of explicit representations of solvent molecules in the simulation.</p>
<aside class="abc" style="margin-top:-10em;" epub:type="sidebar">
<figure class="fig1" id="fig4_2">
<img src="../images/fig4_2.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.2</b>&#x00A0;&#x00A0;Radial distribution function for liquid water. The first and second solvation shells can clearly be seen at sA and 4.5A respectively.</p>
</aside>
<p class="indent">The first obvious disadvantage of this approach is that the size of the calculation is greatly increased. As, for many applications, water is the most interesting solvent, our discussion will be restricted to its representation. Having now increased our calculation to include explicit solvent-solute interactions, it would be expected that all the necessary interactions for reliable simulations will be present. This is not quite the case. The first problem to be overcome is that of system size. All calculations will be carried out on a system of finite size, a box, say. Although the atoms at the centre of the box are receiving their correct complement of interactions those at the faces have a vacuum at one side. This has led to the use of the technique known as periodic boundary conditions (<a href="#fig4_3">Fig. 4.3</a>). The system of interest is surrounded by images of itself (i.e., the system becomes a type of unit cell in an infinite solution). Molecules close to the edge of the real box can now interact with the image molecules in the surrounding boxes, minimizing edge effects. And, if the motions of a molecule cause it to leave the simulation box an image enters from the opposite face, keeping constant the number of molecules in the system. Care must be taken, however, when choosing the box size and interaction cutoff distances. If the box length is less than twice the cutoff distance, a molecule <i>A</i> could interact with both <i>B</i> and one if its images <i>B&#x2019;</i>, setting up the equivalent of a phonon wave in solid state systems</p>
<aside class="abc" style="margin-top:-12em;" epub:type="sidebar">
<figure class="fig1" id="fig4_3">
<img src="../images/fig4_3.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.3</b>&#x00A0;&#x00A0;Periodic boundary conditions.</p>
</aside>
<p class="indent">The second problem concerns the cutoff itself. Using a cutoff of between 8 and 1O&#x00C5; with the various functions representing van der Waals interactions is an adequate approximation given its short-ranged nature. For electrostatic interactions this is not the case. At 8&#x2013;10&#x00C5; the electrostatic energy has still to converge, therefore, truncation introduces possible sources of error. Either one must accept the error or use methods which produce shorter range convergence.</p>
<p class="indent">Explicit representation of solvent can also suffer from the problem that, if only van der Waals and electrostatic interactions are represented, there is still <a id="page_49" class="page">Page 49, Statistical mechanics</a>no account taken of the response of the solvent to the presence of charges, i.e., it cannot be polarized. By using more complex water models, including polarization and many-body contributions, more reliable solvation should be accomplished but at the expense of computing requirements.</p>
</section>
</section>
<section epub:type="chapter" id="sec_4.3">
<h2 class="h2">4.3<span class="space">&#160;</span>Monte Carlo methods</h2>
<p class="noindent">Having set up a system of molecules, we now require methods other than simple energy calculation and minimization to simulate the changes undergone by the system. This can be done using either Monte Carlo methods or molecular dynamics (see <a href="#sec_4.4">Section 4.4</a>).</p>
<p class="indent">If we wish to calculate a particular property <i>(Q)</i> of a system with a constant number of particles, temperature and volume (the canonical ensemble) &#x2013; shortened to (NVT) &#x2013; classical statistical mechanics shows that the average value of that property is given by <a href="#eq4.4">Eqn. 4.4</a></p>
<p class="fig1a" id="eq4.4"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mo>&#x003C;</mo><mi>Q</mi><mo>&#x003E;</mo><mo>=</mo><mo>&#x222B;</mo><mi>Q</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mi>P</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.4</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="fig1a" id="eq4.5"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>P</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>U</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo></mrow><mrow><mo>&#x222B;</mo><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>U</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle></mrow></mfrac><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.5</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where <i>P</i>(X) is the Boltzmann weighted probability, <i>U</i>(X) the internal energy, and X represents all possible states of the system of interest. The problem is how to calculate the probability function <i>P</i>(X) from a collection of molecules acting under a potential field.</p>
<p class="indent">The solution to the integrals above could be found by sampling different configurations of the system to provide an indication of all possible states. In its crudest formulation random moves could be made to different molecules. From the energies calculated at each move it would be possible to obtain estimates of <i>Q</i>(X)<i>P</i>(X), which could then be averaged to produce a value of &#x003C;<i>Q</i>&#x003E;. This approach is clearly flawed since each configuration makes an equal contribution to the configurational integral. Since <i>P</i>(X) is proportional to the Boltzmann factor exp[&#x2122;<i>U</i>(X)/<i>k</i><sub>B</sub><i>T</i>] only configurations with low energies will make a significant contribution to <i>P</i>(X). Hence, many of the configurations generated will have little influence, so proper sampling has not been achieved. The sampling problem was solved in the 1950s by only counting contributions to the configurational integral if they have a probability of occurring proportional to the Boltzmann factor.</p>
<p class="indent">If we consider the transition between two states <i>a</i> and <i>b</i>. By first order kinetics the rate of transition <i>p</i> is given by</p>
<p class="fig1a" id="eq4.6"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>p</mi><mo>=</mo><mstyle displaystyle='true'><mo>&#x2211;</mo> <mrow><mo>&#x2212;</mo><msub><mi>w</mi><mrow><mtext>ab</mtext></mrow></msub><msub><mi>p</mi><mtext>a</mtext></msub><mo>+</mo><msub><mi>w</mi><mrow><mtext>ba</mtext></mrow></msub><msub><mi>p</mi><mtext>b</mtext></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.6</mn><mo stretchy='false'>)</mo></mrow></mstyle></mrow>
</semantics></math></p>
<p class="noindent">where <i>w</i><sub>ab</sub> is the probability that a transition will take place and <i>p</i><sub>a</sub> the probability that a system is in a given state. At equilibrium <i>p</i> = 0 therefore</p>
<p class="fig1a" id="eq4.7"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mo stretchy='false'>(</mo><msub><mi>p</mi><mtext>a</mtext></msub><mo>/</mo><msub><mi>p</mi><mtext>b</mtext></msub><mo stretchy='false'>)</mo><mo>=</mo><mi>e</mi><mi>x</mi><mi>p</mi><mtext>&#x2009;</mtext><mo stretchy='false'>(</mo><mo>&#x2212;</mo><mi>&#x0394;</mi><msub><mi>E</mi><mrow><mtext>ab</mtext></mrow></msub><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>)</mo><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.7</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent"><a id="page_50" class="page">Page 50, Statistical mechanics</a>So the states are related by the Boltzmann constant. Substituting back into <a href="#eq4.6">Eqn. 4.6</a> we have</p>
<p class="fig1a" id="eq4.8"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mo stretchy='false'>(</mo><msub><mi>w</mi><mrow><mtext>ba</mtext></mrow></msub><mo>/</mo><msub><mi>w</mi><mrow><mtext>ab</mtext></mrow></msub><mo stretchy='false'>)</mo><mo>=</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy='false'>(</mo><mo>&#x2212;</mo><mi>&#x0394;</mi><msub><mi>E</mi><mrow><mtext>ab</mtext></mrow></msub><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>)</mo><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.8</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Therefore, the probability that a transition will take place is also Boltzmann weighted. We now have a set of conditions which allow correct sampling of all possible configurations of the system: its phase space.</p>
<p class="fig1a" id="eq4.9"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msub><mi>w</mi><mrow><mtext>ab</mtext></mrow></msub><mo>&#x221D;</mo><mrow><mo>{</mo> <mrow><msubsup><mrow></mrow><mrow><mi>exp</mi><mtext>&#x2009;</mtext><mo stretchy='false'>(</mo><mo>&#x2212;</mo><mi>&#x0394;</mi><mtext>E</mtext><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>)</mo><mo>,</mo><mtext>&#x2009;</mtext><mi>&#x0394;</mi><mtext>E</mtext><mtext>&#x2009;</mtext><mo>&#x003E;</mo><mtext>&#x2009;</mtext><mn>0</mn></mrow><mrow><mn>1</mn><mo>,</mo><mtext>&#x2009;</mtext><mi>&#x0394;</mi><mtext>E</mtext><mtext>&#x2009;</mtext><mtext>&#x2009;</mtext><mo>&#x2264;</mo><mtext>&#x2009;</mtext><mn>0</mn></mrow></msubsup></mrow></mrow><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.9</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="indent">In practice, when dealing with a solute in a box of discrete water molecules, a new configuration is generated by picking one molecule at random, translating it in three dimensions and applying a rotation about one axis. If the limits for the moves are set too high then the number of acceptable configurations will be too low, so these must be carefully chosen. The energy of the new configuration is evaluated and the criteria in <a href="#eq4.9">Eqn. 4.9</a> are applied. If the new configuration has a lower energy than the previous one it is immediately accepted; if it is higher in energy its Boltzmann probability is evaluated and this is compared to a randomly generated number between 0 and 1. If <i>w</i><sub>ab</sub> is higher than the random number the new configuration is accepted, otherwise it is rejected and the system is returned to its previous state. By repeated application of this procedure a correctly weighted set of <i>M</i> configurations is obtained, and the configuration integral in <a href="#eq4.4">Eqn. 4.4</a> can be changed into a summation giving <a href="#eq4.10">Eqn. 4.10</a></p>
<p class="fig1a" id="eq4.10"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mo>&#x003C;</mo><mi>Q</mi><mo>&#x003E;</mo><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><mstyle displaystyle='true'><mo>&#x2211;</mo> <mrow><mi>Q</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><msup><mi>X</mi><mo>&#x2032;</mo></msup></mstyle><mo stretchy='false'>)</mo></mrow></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.10</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where <b>X&#x0027;</b> indicates that only configurations with an acceptable Boltzmann weighted probability have been sampled. This is sometimes referred to as Metropolis sampling.</p>
<p class="indent">Typically, a simulation would start with an equilibration period to allow proper relaxation of the solvent in response to the insertion of solute. These configurations would be discarded and the simulation would enter a production phase of 500,000&#x2013;1,000,000 configurations. Here we have assumed that the individual molecules remain rigid throughout. This can be modified to include, say, solute torsional degrees of freedom but the length of the simulation must also be greatly increased to allow solvent relaxation after each change. As molecules are moved at random there is no provision for collective molecular motion.</p>
<aside class="abc" style="margin-top:-10em;" epub:type="sidebar">
<p class="noindent2">The application of Monte Carlo methods to conformational problems is discussed in Jorgensen, W. L. (1983). <i>J. Phys. Chem</i>., <b>87</b>, 5304&#x2013;5314.</p>
</aside>
<p class="indent">Monte Carlo calculations are particularly useful when investigating the properties of small molecules in solution as the system is not constrained by the barriers on the potential surface. The random nature of the moves allows the system to move easily from one potential well to another without the requisite kinetic energy to overcome the barrier. However, for larger molecular systems, where there may be cooperative motions about internal coordinates, this method is much less successful. For a molecule the size of a protein very many torsional moves would be disallowed unless they were limited to ridiculously low values. In the latter circumstance it would not be <a id="page_51" class="page">Page 51, Statistical mechanics</a>feasible to carry out representative sampling of phase space, hence calculated properties would not be close to convergence. The second disadvantage associated with Monte Carlo simulations is that time-dependent properties such as diffusion coefficients, and rotational and translational correlation functions cannot be monitored. This results from the random nature of the method; the size of an individual move is not controlled by the previous state of the system.</p>
<p class="indent">In addition to calculating statistical averages, the Monte Carlo method has found application in searching procedures. In the previous chapter we viewed conformational analysis from a systematic point of view. If, however, random moves are made to the rotatable bonds of an isolated molecule, using the Metropolis sampling condition it should be possible to generate a large number of suitable conformations. The trajectory of acceptable conformations can then be energy minimized, and ranked by energy. The assumption here is that in a user-defined time it is possible to take a representative sample from low-energy phase space. But to reach this convergence point it is still necessary to generate a large number of conformations.</p>
<p class="indent">Thus, when interested in structural problems, or in systems with few internal degrees of freedom, the Monte Carlo method is the technique of choice. Otherwise, molecular dynamics may be more suitable.</p>
<p class="indent">In the preceding discussion only calculations in the canonical (NVT) ensemble were considered. It is possible to extend the Monte Carlo method to other ensembles by making the appropriate changes to the system. To carry out simulations in the isothermal-isobaric (NPT) ensemble the relationship describing average properties (Eqn. 4.4) becomes</p>
<p class="fig1a" id="eq4.11"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mo>&#x003C;</mo><mi>Q</mi><mo>&#x003E;</mo><mo>=</mo><mo>&#x222B;</mo><mtext>Q</mtext><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo>,</mo><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle><mo stretchy='false'>)</mo><mi>P</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo>,</mo><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle><mo stretchy='false'>)</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mtext>d</mtext><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.11</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where</p>
<p class="fig1a" id="eq4.12"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>P</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi><mo>,</mo><mi>V</mi></mstyle><mo stretchy='false'>)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>H</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo>,</mo><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo></mrow><mrow><mo>&#x222B;</mo><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>H</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo>,</mo><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle></mrow></mfrac><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.12</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">and the enthalpy</p>
<p class="fig1a" id="eq4.13"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>H</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo>,</mo><mstyle mathvariant='bold' mathsize='normal'><mi>V</mi></mstyle><mo stretchy='false'>)</mo><mo>=</mo><mi>U</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>+</mo><mi>P</mi><mi>V</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.13</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Sampling is now over all allowed configurations and all allowed volumes. Therefore, the volume of the system must also be subject to a periodic, random change by appropriate rescaling of all the atomic coordinates. As we will see later, this is not as easy to do in molecular dynamics simulations.</p>
</section>
<section epub:type="chapter" id="sec_4.4">
<h2 class="h2">4.4<span class="space">&#160;</span>Molecular dynamics</h2>
<p class="noindent">In the chemical sciences molecular structures are usually presented as being rigid except for rotatable bonds. This creates a conceptual barrier when one moves from isolated molecules to &#x2018;real&#x2019; systems as no account has been <a id="page_52" class="page">Page 52, Statistical mechanics</a>taken of the fact that the molecule is not in fact rigid, at a minimum energy structure, but is of higher energy, is constantly vibrating along bonds and about bond angles, and is actually somewhere above the fully relaxed potential energy surface. Only when one starts to understand the significance of the dynamic picture of molecules can more complex processes be understood. In biology very large structural changes can take place which would appear to require a massive input of energy. If this process is broken down into a number of smaller changes it becomes apparent that what we are seeing is the cumulative effect of many thermally acceptable excitations. No longer is it necessary, or adequate, to explain these changes as the result of motion of rigid bodies. Unfortunately, many of the changes are not easily observed by experiment, leaving the way open for theoretical methods such as molecular dynamics.</p>
<section epub:type="chapter" id="sec_4.4.1">
<h3 class="h3">The equations of motion</h3>
<p class="noindent">A simple definition of molecular dynamics is that it simulates the motions of a system of particles (atoms) with respect to the forces which are present. For an isolated molecule this would mean the valence forces. If we consider a system consisting of hard spheres with position <b>r</b> acting under some kind of inter-particle potential <i>V</i><b>(r)</b>, say, the Lennard-Jones potential in <a href="Chapter_03.xhtml#ch03">Chapter 3</a>, then it is possible to calculate the forces which are acting on each member of the system as &#x2212;&#x03B4;<i>V</i><b>(r</b>)/&#x03B4;<b>r</b>. The collection of forces should cause the system to change, but by collective motion of particles over time, in a way that is described by integrating Newton&#x2019;s second law of motion</p>
<aside class="abc" style="margin-top:-12em;" epub:type="sidebar">
<p class="noindent2">See Karplus, M. and Petsko, G. A. (1990). <i>Nature</i>, <b>347</b>, 631&#x2013;639, for a review of the application of molecular dynamics to biological problems.</p>
</aside>
<p class="fig1a" id="eq4.14"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msub><mi>F</mi><mtext>i</mtext></msub><mo>=</mo><msub><mi>m</mi><mtext>i</mtext></msub><msub><mi>a</mi><mtext>i</mtext></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.14</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where <i>F</i> is the force acting on a particle, <i>m</i> its mass, and <i>&#x03B1;</i> its acceleration. If we can calculate what the next configuration of the particles is we now have a method to follow the evolution of the system over time. This is distinct from the Monte Carlo method which requires outside intervention in the form of a random move in the system to produce change. In molecular dynamics all changes result from within the system itself, without external intervention.</p>
<p class="indent">If we rearrange <a href="#eq4.14">Eqn. 4.14</a>, and write acceleration as the second derivative of displacement (<i>s</i>) with respect to time, &#x03B4;<sup>2</sup><i>s</i>/&#x03B4;<i>t</i><sup>2</sup>, we have a more usable version of Newton&#x2019;s law</p>
<p class="fig1a" id="eq4.15"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x03B4;</mi><msub><mi>s</mi><mtext>i</mtext></msub><mo>/</mo><mi>&#x03B4;</mi><msup><mi>t</mi><mn>2</mn></msup><mo>=</mo><msub><mi>F</mi><mtext>i</mtext></msub><mo>/</mo><msub><mi>m</mi><mtext>i</mtext></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.15</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Thus to obtain the dynamic behaviour of our system we must solve this second order differential equation for every particle in the system. Integrating with respect to time gives</p>
<p class="fig1a" id="eq4.16"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x03B4;</mi><msub><mi>s</mi><mtext>i</mtext></msub><mo>/</mo><mi>&#x03B4;</mi><mi>t</mi><mo>=</mo><mo stretchy='false'>(</mo><msub><mi>F</mi><mtext>i</mtext></msub><mo>/</mo><msub><mi>m</mi><mtext>i</mtext></msub><mo stretchy='false'>)</mo><mi>t</mi><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.16</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">At time <i>t</i> = 0 the first term vanishes and the velocity is given by the constant <i>c</i><sub>1</sub> the initial velocity <i>u</i><sub>i</sub>. At time <i>t</i> we have</p>
<p class="fig1a" id="eq4.17"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x03B4;</mi><msub><mi>s</mi><mtext>i</mtext></msub><mo>/</mo><mi>&#x03B4;</mi><mi>t</mi><mo>=</mo><msub><mi>a</mi><mi>i</mi></msub><mi>t</mi><mo>+</mo><msub><mi>u</mi><mi>i</mi></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.17</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent"><a id="page_53" class="page">Page 53, Statistical mechanics</a>in other words the expression for velocity at any time. Further integration with respect to time produces</p>
<p class="fig1a" id="eq4.18"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><msub><mi>u</mi><mi>i</mi></msub><mi>t</mi><mo>+</mo><mstyle scriptlevel='+1'><mfrac bevelled='true'><mn>1</mn><mn>2</mn></mfrac></mstyle><msub><mi>a</mi><mi>i</mi></msub><msup><mi>t</mi><mn>2</mn></msup><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.18</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where the constant is the current position. This allows one to calculate the displacement from an initial velocity <i>u</i><sub>i</sub> and the acceleration which can be derived from <i>a</i><sub>i</sub> = <i>F</i><sub>i</sub>/<i>m</i><sub>i</sub>.</p>
<p class="indent">This simple derivation produces an expression which corresponds to the truncated Taylor series for displacement</p>
<p class="fig1a" id="eq4.19"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>x</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>+</mo><mi>&#x0394;</mi><mi>t</mi><mo stretchy='false'>)</mo><mo>=</mo><mi>x</mi><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>+</mo><mfrac><mrow><mi>&#x03B4;</mi><mi>x</mi></mrow><mrow><mi>&#x03B4;</mi><mi>t</mi></mrow></mfrac><mi>&#x0394;</mi><mi>t</mi><mo>+</mo><mfrac><mrow><msup><mi>&#x03B4;</mi><mn>2</mn></msup><mi>x</mi></mrow><mrow><mi>&#x03B4;</mi><msup><mi>t</mi><mn>2</mn></msup></mrow></mfrac><mo>.</mo><mi>&#x0394;</mi><mfrac><mrow><msup><mi>t</mi><mn>2</mn></msup></mrow><mn>2</mn></mfrac><mo>+</mo><mn>...</mn><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.19</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">therefore a small, persistent error is introduced into the calculation at every time step through the neglect of the higher order terms. Note also that the assumption is being made that the acceleration remains constant throughout the timestep &#x0394;<i>t</i>. Unless infinitesimal steps are taken, this is another error-inducing assumption. In practice the time steps used are of the order of 0.5&#x2013;1 femtoseconds (1 fs = 10&#x2212;<sup>15</sup> s), with the restriction that the time difference must be smaller than that for the highest frequency vibration in the system (typically bond stretches). Using a smaller time step with <a href="#eq4.19">Eqn. 4.19</a> would produce fewer errors but would require a complementary increase in computer time to allow the simulation of interesting phenomena.</p>
<p class="indent">A number of algorithms have been developed to overcome the problems associated with finite time steps and truncation errors. Here we shall discuss the derivation of the Leapfrog Verlet method. If we define &#x03BD; as the average velocity over a time step <i>At</i> then the new position is given by</p>
<p class="fig1a" id="eq4.20"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>x</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>+</mo><mi>&#x0394;</mi><mi>t</mi><mo stretchy='false'>)</mo><mo>=</mo><mi>x</mi><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>+</mo><mi>v</mi><mi>&#x0394;</mi><mi>t</mi><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.20</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Assuming that &#x03BD; is almost equal to the velocity at the midpoint of the time interval (<i>(t + &#x0394;t)</i>)</p>
<p class="fig1a" id="eq4.21"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>v</mi><mo>=</mo><mi>v</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>+</mo><mi>&#x0394;</mi><mi>t</mi><mo>/</mo><mn>2</mn><mo stretchy='false'>)</mo><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.21</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">we can now calculate &#x03BD; from the midpoint of the previous interval and the average acceleration between <i>t &#x2212; &#x0394;t</i> and <i>t + &#x0394;t</i>, so</p>
<p class="fig1a" id="eq4.22"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>v</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>+</mo><mi>&#x0394;</mi><mi>t</mi><mo>/</mo><mn>2</mn><mo stretchy='false'>)</mo><mo>=</mo><mi>v</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>&#x2212;</mo><mi>&#x0394;</mi><mi>t</mi><mo>/</mo><mn>2</mn><mo stretchy='false'>)</mo><mo>+</mo><mi>a</mi><mi>&#x0394;</mi><mi>t</mi><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.22</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where <i>a</i> can be calculated from <i>m</i><sup>&#x2212;</sup><i>F(x,t)</i>). Substituting back into <a href="#eq4.20">Eqn. 4.20</a> the new position is given by</p>
<p class="fig1a" id="eq4.23"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>x</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>+</mo><mi>&#x0394;</mi><mi>t</mi><mo stretchy='false'>)</mo><mo>=</mo><mi>x</mi><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>+</mo><mi>v</mi><mo stretchy='false'>(</mo><mi>t</mi><mo>&#x2212;</mo><mi>&#x0394;</mi><mi>t</mi><mo>/</mo><mn>2</mn><mo stretchy='false'>)</mo><mo>+</mo><msup><mi>m</mi><mrow><mo>&#x2212;</mo><mn>1</mn></mrow></msup><mi>F</mi><mo stretchy='false'>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo stretchy='false'>)</mo><mi>&#x0394;</mi><mi>t</mi><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.23</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">By avoiding calculating the velocity and acceleration at the same point in time the errors introduced by the truncation can be minimized.</p>
</section>
<section epub:type="chapter" id="sec_4.4.2">
<a id="page_54" class="page" style="width:70%;">Page 54, Statistical mechanics</a>
<h3 class="h3">Simulation protocols</h3>
<p class="noindent">The next question is how can we use <a href="#eq4.23">Eqn. 4.23</a> to simulate the dynamics of an actual system. Before starting a dynamics simulation the complete system should be minimized to eliminate as many of the poor contacts as possible. Since the algorithm is force driven, the presence of local strain could cause severe problems. The system to be simulated will typically be not unlike those discussed for Monte Carlo simulations. A solute molecule, either a small molecule or a macromolecule, is placed in a box of solvent molecules; edge effects are reduced by the use of periodic boundary conditions. To save computer time, at the expense of accuracy, one can carry out the simulation in the gas phase with an appropriate solvent dielectric constant, or in a sphere of water or in an isolated box. If periodic boundary conditions are not being used it is advisable to divide the system into an inner and outer layer with restraining forces applied to the outer layer of molecules to prevent their &#x2018;evaporation&#x2019;. Having minimized the system, the first stage is to heat it to the required temperature. The temperature of the simulation is calculated from the kinetic energy of all of the atoms in the system</p>
<p class="fig1a" id="eq4.24"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mstyle displaystyle='true'><mo>&#x2211;</mo> <mrow><msub><mi>m</mi><mtext>i</mtext></msub><msubsup><mi>v</mi><mtext>i</mtext><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mi>N</mi><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi></mrow></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.24</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">but at time <i>t</i> = 0 no velocities are known. The system is heated by assigning velocities randomly to the atoms according to a Maxwellian distribution for the given temperature. If a temperature of 300 K is required, a number of intermediate temperatures will be assigned before the system is properly heated. Once the first velocities have been assigned the molecular dynamics method is self-perpetuating; the acceleration is calculated from the forces according to the potential used and the new positions obtained from <a href="#eq4.23">Eqn. 4.23</a>. In the next step the velocities can be calculated by <a href="#eq4.22">Eqn. 4.22</a> and so it continues. During the heating period it is important that the velocities for a new temperature be assigned at random to minimize the development of local, high-temperature &#x2018;hot-spots&#x2019; in the system.</p>
<p class="indent">Once the system has the required velocities it is advisable to go through a period of equilibration. This should allow redistribution of the system&#x2019;s energy to ensure stability. Periodic rescaling of the velocities will also be required to bring the system back to the required temperature. The length of the equilibration period should be dependent on the properties being observed: kinetic energy requires a relatively short relaxation period, of the order of a picosecond, while bulk water requires around 10&#x2013;20 ps. By monitoring system properties such as temperature and the different energy components it should be obvious when they have converged to equilibrium values. Certain programs will not include an explicit equilibration phase but here the user must simply discard the period of the trajectory up until such a time as the system appears stable.</p>
<p class="indent">In the final phase the production dynamics is carried out. The exact nature of this phase is determined by which ensemble is being simulated. In the microcanonical ensemble (NVE) the system undergoes free dynamics with no rescaling of velocities. If the system is sufficiently stabilized by the equilibration phase then this is easy to do. However, if the temperature starts <a id="page_55" class="page">Page 55, Statistical mechanics</a>to drift there is no way of controlling the system. Drift of this type often occurs as a result of the truncation of the long-range electrostatic forces. If the canonical ensemble is required, close monitoring of the system must be applied. This can be done by adding temperature as an additional degree of freedom to the system. This requires the specification of a &#x2018;mass&#x2019; associated with temperature so there is dynamic transfer of heat to and from the system as required. However, this can set up energy oscillations. A different method is to rescale the temperature at every step using the multiplier &#x03BB;, where</p>
<p class="fig1a" id="eq4.25"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mtext>&#x03BB;</mtext><mo>=</mo><msup><mrow><mrow><mo>[</mo> <mrow><mn>1</mn><mo>+</mo><mfrac><mrow><mi>&#x0394;</mi><mtext>t</mtext></mrow><mrow><msub><mi>&#x03C4;</mi><mtext>T</mtext></msub></mrow></mfrac><mrow><mo>(</mo><mrow><mfrac><mrow>
  <msub>
  <mtext>T</mtext>
  <mtext>0</mtext>
  </msub>
  </mrow><mtext>T</mtext></mfrac><mo>&#x2212;</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow> <mo>]</mo></mrow></mrow><mrow><mstyle scriptlevel='+1'><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle></mrow></msup><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.25</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Here <i>T</i><sub>0</sub> is the desired temperature and &#x03C4;<sub>T</sub> is a coupling parameter characteristic of the relaxation time of the system. In practice, &#x03C4;<sub>T</sub> is an adjustable parameter which determines how tight the velocity rescaling is; if it is sufficiently weak, the system is not disturbed too much. One disadvantage of this method is that the system no longer exactly corresponds to one of the classical ensembles. Similar procedures can be used to control the pressure of a system, but here it is the coordinates of the atoms which are rescaled.</p>
<p class="indent">For a large system (thousands of atoms) a dynamics simulation is very computationally intensive and one is limited as to which properties can be observed. Unless a very fast computer is being used, most simulations will be restricted to hundreds of picoseconds, but even here the time taken will be weeks or months. It was stated earlier that a major limitation on the length of a time step is the high frequency vibrations of bonds. If these could be constrained in some way then it would be possible to use time steps of around 2 ps, allowing twice the length of simulation. Clearly one cannot simply place a high force constant in the bond stretching potential function as this would bias the moves due to other terms. The SHAKE procedure is one of the most commonly used methods to get around this problem. The first stage is to move the atoms as calculated by the Verlet algorithm without considering constraints. It is then possible to calculate corrections to the position of each atom in turn such that they satisfy the condition that the bond length is within some set tolerance of its previous value. Since each bond is considered on its own all the conditions will not be met in one cycle of constraints so a solution must be obtained by iterating over all of the relevant bonds. Studies have shown that these constraints do not alter significantly the calculated trajectory. A typical overhead for the calculation is about 10(%) which compares favourably with the advantage of obtaining a double length simulation.</p>
<p class="indent">In many applications one is interested in only a fraction of the system being simulated e.g., in enzyme-inhibitor studies only the active site and its immediate surroundings are important. Therefore, much of the computer time used is essentially wasted. Fortunately, methods have been developed to overcome this problem and simulations can be carried out using stochastic dynamics methods. First, the system must be divided up into a number of regions (<a href="#fig4_4">Fig. 4.4</a>). The first region is spherical and centred on the area of <a id="page_56" class="page">Page 56, Statistical mechanics</a>interest; this segment will be treated explicitly in the simulation. In the second region, a shell surrounding the first, the atoms&#x2019; motions are simulated using a modified equation of motion, the Langevin equation</p>
<p class="fig1a" id="eq4.26"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msup><mtext>d</mtext><mn>2</mn></msup><msub><mi>r</mi><mi>i</mi></msub><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>/</mo><mi>d</mi><msup><mi>t</mi><mn>2</mn></msup><mo>=</mo><msubsup><mi>m</mi><mtext>i</mtext><mrow><mo>&#x2212;</mo><mn>1</mn></mrow></msubsup><mi>F</mi><mo>+</mo><msubsup><mi>m</mi><mtext>i</mtext><mrow><mo>&#x2212;</mo><mn>1</mn></mrow></msubsup><mi>R</mi><mo>&#x2212;</mo><msub><mtext>&#x03B3;</mtext><mtext>i</mtext></msub><msub><mrow><mtext>dr</mtext></mrow><mtext>i</mtext></msub><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>/</mo><mi>d</mi><mi>t</mi><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.26</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<aside class="abc" style="margin-top:-4em;" epub:type="sidebar">
<figure class="fig1" id="fig4_4">
<img src="../images/fig4_4.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.4</b>&#x00A0;&#x00A0;Partitioning of a system for stochastic dynamics. Only those atoms within the circle will be simulated explicitly.</p>
</aside>
<p class="noindent">where the first term on the right hand side is as before; the second term allows for the introduction of energy to the main region using the stochastic (random) force <i>R</i>, while the third, frictional term allows dissipation of kinetic energy from the reaction region to the surroundings; in effect representing vibrational damping of the inner regions by the outer zone. This last region of the system is kept fixed in space. In this way the middle region acts as a buffer between the explicitly dynamic portion of the system and the fixed region. This method could cause difficulties, however, when calculating thermodynamic properties; the treatment of long range electrostatic forces is inadequate and temperature and pressure control difficult.</p>
</section>
<section epub:type="chapter" id="sec_4.4.3">
<h3 class="h3">Analysing the trajectory</h3>
<p class="noindent">Having carried out a dynamics simulation, and collected representative structures throughout the trajectory, what information can be gleaned by analysis of the data? The most obvious data are structural: root-mean-squared differences between the starting and final structure, or an average structure over the whole trajectory. If more detailed conformational information is required then plots of individual dihedral angles versus time can show when such changes take place; one of the first applications of molecular dynamics to biological problems was to observe aromatic ring flips in the interior of the protein bovine pancreatic trypsin inhibitor. Fluctuations about average positions can also be correlated with temperature factors from x-ray structures.</p>
<p class="indent">One major advantage over Monte Carlo simulations is that time-dependent properties can now be calculated. These can include properties such as diffusion coefficients, which are calculated from mean-square displacements of a particle over time, and correlation functions which give a quantitative measure of the relaxation of features such as reorientation of solvent molecules. Correlation functions have the general form</p>
<p class="fig1a" id="eq4.27"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msub><mi>C</mi><mtext>A</mtext></msub><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>=</mo><mfrac><mrow><mo>&#x2329;</mo><msub><mi>A</mi><mtext>i</mtext></msub><mo stretchy='false'>(</mo><mn>0</mn><mo stretchy='false'>)</mo><msub><mi>A</mi><mtext>i</mtext></msub><mo stretchy='false'>(</mo><mi>t</mi><mo stretchy='false'>)</mo><mo>&#x232A;</mo></mrow><mrow><mo>&#x2329;</mo><msubsup><mi>A</mi><mtext>i</mtext><mn>2</mn></msubsup><mo>&#x232A;</mo></mrow></mfrac><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.27</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">and show the relationship between a property <i>A</i> of a particle at time = 0 and time = <i>t</i>. This is averaged over all relevant molecules in the system and plotted for a series of times. By fitting this curve to an appropriate function the rate of decay is obtained, and hence the relaxation time. A typical set of water reorientation functions is shown in <a href="#fig4_5">Fig. 4.5</a>.</p>
<p class="indent">Finally, detailed energetic data are immediately available from a molecular dynamics simulation. From a plot of potential energy versus time it is easy to see when a major change has taken place; these should show up as changes in energy. By comparing energy traces to, say, dihedral angle terms from a simulation, we can get some idea of the real barriers for <a id="page_57" class="page">Page 57, Statistical mechanics</a>conformational changes. The behaviour of a real molecule is not well described by the minimum energy surface described in <a href="Chapter_03.xhtml#ch03">Chapter 3</a> so the barrier heights will not be accurate. Energies extracted from dynamics simulations should show the actual barriers (within the limits of the force field) and, in many cases, a number of barrier crossings will take place allowing estimates in both directions. Molecular dynamics also can be used to generate ensemble averages required for the thermodynamic relationships presented in <a href="#eq4.4">Eqns. 4.4</a> and <a href="#eq4.5">4.5</a>, if one assumes that, over the duration of a simulation, a correctly sampled distribution of configurations and conformations has been sampled. In principle, this should be the case, but molecular dynamics simulations require energy to traverse energy barriers so the system could remain in a potential well, whereas in Monte Carlo simulations the random changes allow the system to move easily between potential wells. A more detailed discussion of the calculation of free energies from simulation is given in the <a href="#sec_4.5">Section 4.5</a>.</p>
<aside class="abc" style="margin-top:-14em;" epub:type="sidebar">
<figure class="fig1" id="fig4_5">
<img src="../images/fig4_5.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.5</b>&#x00A0;&#x00A0;Reorientation correlation functions for water molecules solvating various cations. Fitting an exponential function to each curve allows the differential rotational rates to be estimated.</p>
</aside>
</section>
<section epub:type="chapter" id="sec_4.4.4">
<h3 class="h3">Structure refinement</h3>
<p class="noindent">The preceding discussion has concentrated on following properties over the duration of the simulation. Molecular dynamics has also proved to be a particularly useful tool in structure determination, most notably NMR. The existence of much higher field spectrometers and the development of sophisticated multi-dimensional NMR techniques now allows the assignment of most protons on a protein of up to 150 residues. Using different experiments one can get an idea of which protons are close in space through the measurement of nuclear Overhauser effects (nOes); the nOe falls off according to <i>r</i><sup>&#x2212;6</sup> so upper limits can be placed on the distances and the signals can be categorized as strong or weak. This distance information can now be used as a penalty function in the potential energy expression such that deviations from the preset limits result in an increase in energy. A simple harmonic function, relating the nOe estimated distance <i>R</i><sub>NOE</sub>) to the distance in the simulation (<i>R</i><sub>i</sub>), is typically used</p>
<p class="fig1a" id="eq4.28"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msub><mi>E</mi><mrow><mtext>pen</mtext></mrow></msub><mo>=</mo><msup><mrow><mstyle displaystyle='true'><mo>&#x2211;</mo> <mrow><mi>A</mi><mo stretchy='false'>(</mo><msub><mi>R</mi><mtext>i</mtext></msub><mo>&#x2212;</mo><msub><mi>R</mi><mrow><mtext>NOE</mtext></mrow></msub><mo stretchy='false'>)</mo></mrow></mstyle></mrow><mn>2</mn></msup><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.28</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">with <i>A</i> being the equivalent of a force constant. Carrying out molecular dynamics simulations from arbitrary, model conformations produces an ensemble of structures which satisfy the constraints; most notably, there is greater divergence in the flexible regions of the protein than in the regular secondary structure regions. A similar technique is also used in x-ray crystallography with the penalty function acting on the difference between observed structure factors and those calculated from the simulated structure.</p>
<p class="indent">There is one major difference between the dynamics techniques used for structure determination and those discussed earlier. In the former a technique known as simulated annealing is applied; the procedure is similar in principle to that of heating up a metal to very elevated temperatures, where greater motion is possible, allowing more optimum arrangements to be adopted. This is followed by a rapid quench to 0 K. Practically, the model structures are heated up to temperatures of the order of 10,000 K where the structure can traverse a greater range of the available coordinate space than at lower <a id="page_58" class="page">Page 58, Statistical mechanics</a>temperatures. This has the effect of allowing the constraint terms to drive the structure to a suitable conformation. The protein can then be cooled by velocity scaling and energy minimized to relieve any residual strain. The advantage of the elevated temperatures is that a wider radius of convergence is obtained for the structures whereas local minima in the potential energy surface would dominate at lower temperatures.</p>
</section>
</section>
<section epub:type="chapter" id="sec_4.5">
<h2 class="h2">4.5<span class="space">&#160;</span>Free energy calculations</h2>
<p class="noindent">In theory, it should now be possible to calculate the free energy of any system which is amenable to simulation by molecular dynamics or Monte Carlo methods. In practice this is not the case. For a system of particles (or molecules) in the canonical ensemble the expression for the Helmholtz free energy is given in terms of the partition function <i>Z</i> by</p>
<p class="fig1a" id="eq4.29"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>A</mi><mo>=</mo><mo>&#x2212;</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mi>ln</mi><mi>Z</mi><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.29</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="indent">where <i>k<sub>B</sub></i> and <i>T</i> have their usual values. The partition function <i>Z</i> can be written as an integral involving <i>E</i>(X), the configurational energy, over the phase space of the system dX. Thus</p>
<aside class="abc" style="margin-top:-7em;" epub:type="sidebar">
<p class="noindent2">A more detailed discussion of the methods in this section can be found in Reynolds, C. A., King, P. M., and Richards, W. G. (1992). <i>Mot. Phys</i>., <b>76</b>, 251&#x2013;275, and Beveridge, D. L. and DiCapua, F. M. (1989). <i>Ann. Rev. Biophys. Biophys. Chem.,</i> <b>18</b>, 431&#x2013;492.</p>
</aside>
<p class="fig1a" id="eq4.30"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>Z</mi><mo>=</mo><msup><mrow><mo stretchy='false'>(</mo><mn>8</mn><msup><mi>&#x03C0;</mi><mn>2</mn></msup><mi>V</mi><mo stretchy='false'>)</mo></mrow><mrow><mo>&#x2212;</mo><mtext>N</mtext></mrow></msup><mo>&#x222B;</mo><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.30</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Therefore, if we could evaluate <i>Z</i> directly, the free energy of the system would be amenable. In fact, it is much easier to calculate relative free energies between processes than to evaluate absolute free energies. This is a result of the problems associated with convergence of the ensemble averages using simulation techniques. First we will show why this is the case. If we generate an expression equal to 1 of the form</p>
<p class="fig1a" id="eq4.31"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mn>1</mn><mo>=</mo><msup><mrow><mo stretchy='false'>(</mo><mn>8</mn><msup><mi>&#x03C0;</mi><mn>2</mn></msup><mi>V</mi><mo stretchy='false'>)</mo></mrow><mrow><mo>&#x2212;</mo><mtext>N</mtext></mrow></msup><mstyle displaystyle='true'><mrow><mo>&#x222B;</mo><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>+</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo></mrow></mrow></mstyle><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.31</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">and insert this into <a href="#eq4.29">Eqn. 4.29</a>, with inversion of the logarithm we get</p>
<p class="fig1a" id="eq4.32"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>A</mi><mo>=</mo><msub><mi>k</mi><mi>B</mi></msub><mi>T</mi><mi>ln</mi><mrow><mo>[</mo> <mrow><mfrac><mrow><mstyle displaystyle='true'><mrow><mo>&#x222B;</mo><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>+</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub>
  <mi>k</mi>
  <mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub>
  <mi>k</mi>
  <mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle></mrow></mrow></mstyle></mrow><mrow><mstyle displaystyle='true'><mrow><mo>&#x222B;</mo><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub>
  <mi>k</mi>
  <mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle></mrow></mrow></mstyle></mrow></mfrac></mrow> <mo>]</mo></mrow><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.32</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">or</p>
<p class="fig1a" id="eq4.33"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>A</mi><mo>=</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mi>ln</mi><mrow><mo>[</mo> <mrow><mstyle displaystyle='true'><mrow><mo>&#x222B;</mo><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>+</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>P</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle></mrow></mrow></mstyle></mrow> <mo>]</mo></mrow><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.33</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where <i>P</i>(X) is the probability function for the system. This can be written more compactly as</p>
<p class="fig1a" id="eq4.34"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>A</mi><mo>=</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mi>ln</mi><mo>&#x003C;</mo><mi>exp</mi><mo stretchy='false'>[</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mo>&#x003E;</mo><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.34</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where &#x003C;&#x2026;&#x003E; represents an ensemble average.</p>
<a id="page_59" class="page" style="width:70%;">Page 59, Statistical mechanics</a>
<p class="indent">This expression can be expanded first, through the exponential, and then the logarithm, to give</p>
<p class="fig1a" id="eq4.35"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>A</mi><mo>=</mo><mo>&#x003C;</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>&#x003E;</mo><mo>&#x2212;</mo><mo>&#x003C;</mo><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><msup><mo>&#x003E;</mo><mn>2</mn></msup><mo>/</mo><mn>2</mn><mo>!</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo>+</mo><mn>...</mn><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.35</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">highlighting the problem that the absolute free energy is given by an ensemble average of the energy, which converges relatively quickly, but also the energy squared and additional higher order terms. Obtaining convergence of the squared, cubic and higher order terms is not rapid because the higher energy configurations of the system play a greater role. It is precisely these regions of phase space which molecular dynamics and Monte Carlo are designed to neglect.</p>
<p class="indent">If we now consider the expression for a free energy difference</p>
<p class="fig1a" id="eq4.36"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><mi>A</mi><mo>=</mo><msub><mi>A</mi><mn>1</mn></msub><mo>&#x2212;</mo><msub><mi>A</mi><mn>0</mn></msub><mo>=</mo><mo>&#x2212;</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mi>ln</mi><mrow><mo>(</mo><mrow><mfrac><mrow><msub><mi>Z</mi><mn>1</mn></msub></mrow><mrow><msub><mi>Z</mi><mn>0</mn></msub></mrow></mfrac></mrow><mo>)</mo></mrow><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.36</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">where <i>Z</i><sub>1</sub> and <i>Z</i><sub>0</sub> are the appropriate partition functions for the two states, it is possible to derive an exact expression for &#x0394;<i>A</i>.</p>
<p class="indent">If we insert a unity in the form of</p>
<aside class="abc" style="margin-top:-3em;" epub:type="sidebar">
<figure class="fig1" id="fig4_6">
<img src="../images/fig4_6.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.6</b>&#x00A0;&#x00A0;The simulation protocol for &#x2018;windowing&#x2019;. The initial and final states are linked via the two intermediate states defined by A. For each value of A the system must be equilibrated (MDeq) prior to data collection (MOde)' For a system at equilibrium the free energy difference can be calculated in both directions simultaneously.</p>
</aside>
<p class="fig1a" id="eq4.37"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mn>1</mn><mo>=</mo><mi>exp</mi><mo stretchy='false'>[</mo><mo>+</mo><msub><mi>E</mi><mn>0</mn></msub><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy='false'>[</mo><mo>+</mo><msub><mi>E</mi><mn>0</mn></msub><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.37</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">into <a href="#eq4.36">Eqn. 4.36</a> we get</p>
<p class="fig1a" id="eq4.38"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><mi>A</mi><mo>=</mo><mo>&#x2212;</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mi>ln</mi><mrow><mo>[</mo> <mrow><mfrac><mrow><mstyle displaystyle='true'><mrow><mo>&#x222B;</mo><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><msub>
  <mi>E</mi>
  <mn>1</mn></msub><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub>
  <mi>k</mi>
  <mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo></mrow></mrow></mstyle><mi>exp</mi><mo stretchy='false'>[</mo><mo>+</mo><msub><mi>E</mi><mn>0</mn></msub><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><msub><mi>E</mi><mn>0</mn></msub><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mi>d</mi><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle></mrow><mrow><mstyle displaystyle='true'><mrow><mo>&#x222B;</mo><mrow><mi>exp</mi><mo stretchy='false'>[</mo><mo>&#x2212;</mo><msub>
  <mi>E</mi>
  <mn>0</mn></msub><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub>
  <mi>k</mi>
  <mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo></mrow></mrow></mstyle><mtext>d</mtext><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle></mrow></mfrac></mrow> <mo>]</mo></mrow><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.38</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">therefore</p>
<p class="fig1a" id="eq4.39"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><mi>A</mi><mo>=</mo><mo>&#x2212;</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mi>ln</mi><msub><mrow><mo>&#x2329;</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy='false'>[</mo><mi>&#x0394;</mi><mi>E</mi><mo stretchy='false'>(</mo><mstyle mathvariant='bold' mathsize='normal'><mi>X</mi></mstyle><mo stretchy='false'>)</mo><mo>/</mo><msub><mi>k</mi><mtext>B</mtext></msub><mi>T</mi><mo stretchy='false'>]</mo><mo>&#x232A;</mo></mrow><mn>0</mn></msub><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.39</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">Now the free energy difference can be obtained as an ensemble average over representative configurations of the initial state of the system.</p>
<p class="indent">The main requirement for the use of this method is that the energy difference between the two states, &#x0394;<i>E</i>(X), must be &#x003C; <i>k</i><sub>B</sub><i>T</i> for proper convergence. Since many chemical applications will give greater energy differences one must divide the transformation into a number of windows with the total free energy difference arising from a sum over all windows. To do this we require a coupling parameter &#x03BB; which links the energy expression for the two limiting states. A mixed energy function can be formed to represent intermediate states</p>
<p class="fig1a" id="eq4.40"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><msub><mi>E</mi><mtext>&#x03BB;</mtext></msub><mo stretchy='false'>(</mo><mi mathvariant='double-struck'>X</mi><mo stretchy='false'>)</mo><mo>=</mo><mtext>&#x03BB;</mtext><msub><mi>E</mi><mtext>A</mtext></msub><mo>+</mo><mo stretchy='false'>(</mo><mn>1</mn><mo>&#x2212;</mo><mtext>&#x03BB;</mtext><mo stretchy='false'>)</mo><msub><mi>E</mi><mtext>B</mtext></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.40</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">The coupling parameter is varied from 0 at the start of simulation 1 through to 1 over a number of intermediate simulations, each with a different mixed energy potential. <a href="#fig4_6">Fig. 4.6</a> illustrates the windowing procedure.</p>
<a id="page_60" class="page" style="width:70%;">Page 60, Statistical mechanics</a>
<p class="indent">The principal advantage of the perturbation formula (Eqn. 4.39) when used with computer simulations is that there is no requirement that the free energy change must take place over a physical pathway. <a href="#fig4_7">Figure 4.7</a> shows the thermodynamic cycle for association of two different molecules <i>S</i><sub>1</sub> and <i>S</i><sub>2</sub> with a macromolecule (an enzyme, for example) <i>X</i>. Experimentalists could obtain a free energy difference for the binding of <i>S</i><sub>1</sub> or <i>S</i><sub>2</sub> to <i>X</i>. Since free energy is a state function, its value does not depend on the pathway taken, so for the closed cycle in <a href="#fig4_7">Fig. 4.7</a> we have</p>
<p class="fig1a" id="eq4.41"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><msub><mi>G</mi><mn>1</mn></msub><mo>&#x2212;</mo><mi>&#x0394;</mi><msub><mi>G</mi><mn>3</mn></msub><mo>=</mo><mi>&#x0394;</mi><msub><mi>G</mi><mn>2</mn></msub><mo>&#x2212;</mo><mi>&#x0394;</mi><msub><mi>G</mi><mn>4</mn></msub><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.41</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent">To simulate the binding steps, &#x0394;<i>G</i><sub>1</sub> and &#x0394;<i>G</i><sub>3</sub>, would be an enormous task as, not just ligand binding, but desolvation of the ligand and the binding site would be required. Using <a href="#eq4.39">Eqn. 4.39</a> it should be possible to calculate the non-physical processes on the vertical axes of <a href="#fig4_7">Fig. 4.7</a> by using the windowing procedure to effect a transformation of <i>S</i><sub>1</sub> to <i>S</i><sub>2</sub> over a number of stages. Thus, the two simulations would be the transformation of <i>S</i><sub>1</sub> into <i>S</i><sub>2</sub> in solution, and converting <i>S</i><sub>1</sub> into <i>S</i><sub>2</sub> at the binding site. Clearly, as long as <i>S</i><sub>1</sub> and <i>S</i><sub>2</sub> are not too different, these changes should not disturb either system duly.</p>
<p class="indent">Since its first application to biological systems in the 1980s a vast number of interesting applications have been investigated using this form of computer alchemy. If the transformation of <i>A</i> to <i>B</i> is calculated in both a hydrophobic and hydrophilic solvent, partition coefficients can be obtained. Mutating one residue type to another in a protein allows the estimation of the effect of the mutant on binding or stability. If a substrate is modified in solution and at the active site, binding energies will result, and by mutating the protonated and unprotonated forms of a molecule we can obtain values of p<i>K</i><sub>a</sub>. Many other applications can be found in the Further Reading.</p>
<aside class="abc" style="margin-top:-11em;" epub:type="sidebar">
<figure class="fig1" id="fig4_7">
<img src="../images/fig4_7.jpg" alt="images"/>
</figure>
<p class="fcaption1"><b>Fig. 4.7</b>&#x00A0;&#x00A0;A typical closed thermodynamic cycle for the binding of two different binding agents, S<sub>1</sub> and S<sub>2</sub>, to a macromolecule, X.</p>
</aside>
<p class="indent">The principal problem with this method is that the two states <i>A</i> and <i>B</i> must differ in such a way that they both affect their environment in similar ways. If the changes are too great then the simulations will have to be longer to allow convergence, or the average over the initial state will not be valid. Depending on the exact nature of the system, either molecular dynamics or Monte Carlo simulations can be used. Obviously each simulation must be long enough to ensure correct sampling of phase space.</p>
<p class="indent">A second method for evaluating free energy differences is thermodynamic integration. If we again describe the transformation by a coupling parameter &#x03BB;, the free energy change can be calculated as</p>
<p class="fig1a" id="eq4.42"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><mi>A</mi><mo>=</mo><mstyle displaystyle='true'><mrow><msubsup><mo>&#x222B;</mo><mtext>0</mtext><mtext>1</mtext></msubsup><mrow><mtext>(&#x03B4;A(&#x03BB;)/&#x03B4;&#x03BB;)</mtext><mtext>&#x2009;</mtext></mrow></mrow></mstyle><mtext>d&#x03BB;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mtext>(4</mtext><mtext>.42)</mtext></mrow>
</semantics></math></p>
<p class="noindent">From this expression it is possible to derive the relationship</p>
<p class="fig1a" id="eq4.43"><math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics><mrow><mi>&#x0394;</mi><mi>A</mi><mo stretchy='false'>(</mo><msub><mi>&#x03BB;</mi><mtext>A</mtext></msub><mo>&#x2192;</mo><msub><mi>&#x03BB;</mi><mtext>B</mtext></msub><mo stretchy='false'>)</mo><mo>=</mo><mstyle displaystyle='true'><munder><mo>&#x2211;</mo><mtext>N</mtext></munder><mrow><mi>&#x0394;</mi><mtext>E</mtext></mrow></mstyle><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x0009;</mtext><mtext>&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;</mtext><mo stretchy='false'>(</mo><mn>4.43</mn><mo stretchy='false'>)</mo></mrow>
</semantics></math></p>
<p class="noindent"><a id="page_61" class="page">Page 61, Statistical mechanics</a>so that by gradually transforming one state to another over N steps we can calculate the free energy difference as being a potential energy difference. Similar criteria for the magnitude apply as for the perturbation formula.</p>
<p class="indent">If the transformation is conformational, it might be more convenient to calculate the free energy difference as a potential of mean force over the conformational degree of freedom. This method is not discussed here but can be found elsewhere.</p>
</section>
<section epub:type="chapter" id="sec_4.6">
<h2 class="h2">4.6<span class="space">&#160;</span>Summary</h2>
<p class="noindent">Many of the chemical processes of interest to computational chemists occur not in the gas phase but in solution. This requires an adequate representation of the solvent environment. The simplest methods for the simulation of the solvent are concerned with electrostatic screening and are incorporated in the calculation <i>via</i> the dielectric constant. Unfortunately this neglects effects due to solvent packing around the solute and, since the molecule is still isolated, provides no information about the molecular behaviour of the solvent. If the latter is of interest it is necessary to incorporate an appropriate number of explicitly defined solvent molecules into the calculation. The intermolecular interactions can be described by suitable molecular mechanics parameters. Restrictions in computer time will usually limit the number of solvent molecules giving rise to spurious effects at the edges of the finite system. This can be overcome by using a square or rectangular system which can then be surrounded by images of itself such that edge molecules interact with images rather than a surrounding vacuum. This is known as applying periodic boundary conditions.</p>
<p class="indent">Two principal methods are applied to the simulation of collections of molecules. Each can be used to generate representative configurations for the calculation of ensemble averaged properties. In the first, the Monte Carlo technique, random moves are made to the molecules and the energy differences tested according to their Boltzmann weighted probability of existing. Only likely configurations contribute to the ensemble average. In the molecular dynamics method all changes are made subject to the inter-and intramolecular forces present in the system, <i>via</i> classical equations of motion. This allows time-dependent behaviour such as diffusion coefficients and relaxation times to be monitored.</p>
<p class="indent">Although absolute free energies cannot easily be obtained from simulations, free energy perturbation methods allow the calculation of their relative values. Often the energy difference must be calculated over a number of intermediate states using a coupling parameter &#x03BB; to define a mixed potential function. This has the advantage of allowing the simulation of non-physical transformations and has opened up the opportunities to obtain calculated values of many different free energy related properties.</p>
</section>
</section>
</body>
</html>